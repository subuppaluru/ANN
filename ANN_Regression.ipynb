{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN_Regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SIFUdmbnL57I"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "column_names=['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
        "boston_df = pd.read_csv(\"housing.csv\",header=None,delimiter=r\"\\s+\",names=column_names)"
      ],
      "metadata": {
        "id": "UxqEy-bvMDhE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boston_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8atw0uHVMJc6",
        "outputId": "ed232ce6-eae7-4aa9-e8c0-adc6d18449c0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8b8f4c07-bc96-4fe6-b086-448a33a21f92\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>MEDV</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b8f4c07-bc96-4fe6-b086-448a33a21f92')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8b8f4c07-bc96-4fe6-b086-448a33a21f92 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8b8f4c07-bc96-4fe6-b086-448a33a21f92');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      CRIM    ZN  INDUS  CHAS    NOX  ...    TAX  PTRATIO       B  LSTAT  MEDV\n",
              "0  0.00632  18.0   2.31     0  0.538  ...  296.0     15.3  396.90   4.98  24.0\n",
              "1  0.02731   0.0   7.07     0  0.469  ...  242.0     17.8  396.90   9.14  21.6\n",
              "2  0.02729   0.0   7.07     0  0.469  ...  242.0     17.8  392.83   4.03  34.7\n",
              "3  0.03237   0.0   2.18     0  0.458  ...  222.0     18.7  394.63   2.94  33.4\n",
              "4  0.06905   0.0   2.18     0  0.458  ...  222.0     18.7  396.90   5.33  36.2\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "boston_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmkkYbaOMObc",
        "outputId": "0aa9d0cc-2e12-4f67-f9f3-a10b5f9832e7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 506 entries, 0 to 505\n",
            "Data columns (total 14 columns):\n",
            " #   Column   Non-Null Count  Dtype  \n",
            "---  ------   --------------  -----  \n",
            " 0   CRIM     506 non-null    float64\n",
            " 1   ZN       506 non-null    float64\n",
            " 2   INDUS    506 non-null    float64\n",
            " 3   CHAS     506 non-null    int64  \n",
            " 4   NOX      506 non-null    float64\n",
            " 5   RM       506 non-null    float64\n",
            " 6   AGE      506 non-null    float64\n",
            " 7   DIS      506 non-null    float64\n",
            " 8   RAD      506 non-null    int64  \n",
            " 9   TAX      506 non-null    float64\n",
            " 10  PTRATIO  506 non-null    float64\n",
            " 11  B        506 non-null    float64\n",
            " 12  LSTAT    506 non-null    float64\n",
            " 13  MEDV     506 non-null    float64\n",
            "dtypes: float64(12), int64(2)\n",
            "memory usage: 55.5 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "boston_df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "Ju2J8QpSMV1r",
        "outputId": "866d8fa4-9d24-404f-8d2e-d2922d6aac8f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0a7e9d5b-6cb4-4f57-aeda-2310a1fc8f3c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>MEDV</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.613524</td>\n",
              "      <td>11.363636</td>\n",
              "      <td>11.136779</td>\n",
              "      <td>0.069170</td>\n",
              "      <td>0.554695</td>\n",
              "      <td>6.284634</td>\n",
              "      <td>68.574901</td>\n",
              "      <td>3.795043</td>\n",
              "      <td>9.549407</td>\n",
              "      <td>408.237154</td>\n",
              "      <td>18.455534</td>\n",
              "      <td>356.674032</td>\n",
              "      <td>12.653063</td>\n",
              "      <td>22.532806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>8.601545</td>\n",
              "      <td>23.322453</td>\n",
              "      <td>6.860353</td>\n",
              "      <td>0.253994</td>\n",
              "      <td>0.115878</td>\n",
              "      <td>0.702617</td>\n",
              "      <td>28.148861</td>\n",
              "      <td>2.105710</td>\n",
              "      <td>8.707259</td>\n",
              "      <td>168.537116</td>\n",
              "      <td>2.164946</td>\n",
              "      <td>91.294864</td>\n",
              "      <td>7.141062</td>\n",
              "      <td>9.197104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.006320</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.460000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.385000</td>\n",
              "      <td>3.561000</td>\n",
              "      <td>2.900000</td>\n",
              "      <td>1.129600</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>187.000000</td>\n",
              "      <td>12.600000</td>\n",
              "      <td>0.320000</td>\n",
              "      <td>1.730000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.082045</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.190000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.449000</td>\n",
              "      <td>5.885500</td>\n",
              "      <td>45.025000</td>\n",
              "      <td>2.100175</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>279.000000</td>\n",
              "      <td>17.400000</td>\n",
              "      <td>375.377500</td>\n",
              "      <td>6.950000</td>\n",
              "      <td>17.025000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.256510</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.690000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.538000</td>\n",
              "      <td>6.208500</td>\n",
              "      <td>77.500000</td>\n",
              "      <td>3.207450</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>330.000000</td>\n",
              "      <td>19.050000</td>\n",
              "      <td>391.440000</td>\n",
              "      <td>11.360000</td>\n",
              "      <td>21.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.677082</td>\n",
              "      <td>12.500000</td>\n",
              "      <td>18.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.624000</td>\n",
              "      <td>6.623500</td>\n",
              "      <td>94.075000</td>\n",
              "      <td>5.188425</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>666.000000</td>\n",
              "      <td>20.200000</td>\n",
              "      <td>396.225000</td>\n",
              "      <td>16.955000</td>\n",
              "      <td>25.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>88.976200</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>27.740000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.871000</td>\n",
              "      <td>8.780000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>12.126500</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>711.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>396.900000</td>\n",
              "      <td>37.970000</td>\n",
              "      <td>50.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a7e9d5b-6cb4-4f57-aeda-2310a1fc8f3c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0a7e9d5b-6cb4-4f57-aeda-2310a1fc8f3c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0a7e9d5b-6cb4-4f57-aeda-2310a1fc8f3c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             CRIM          ZN       INDUS  ...           B       LSTAT        MEDV\n",
              "count  506.000000  506.000000  506.000000  ...  506.000000  506.000000  506.000000\n",
              "mean     3.613524   11.363636   11.136779  ...  356.674032   12.653063   22.532806\n",
              "std      8.601545   23.322453    6.860353  ...   91.294864    7.141062    9.197104\n",
              "min      0.006320    0.000000    0.460000  ...    0.320000    1.730000    5.000000\n",
              "25%      0.082045    0.000000    5.190000  ...  375.377500    6.950000   17.025000\n",
              "50%      0.256510    0.000000    9.690000  ...  391.440000   11.360000   21.200000\n",
              "75%      3.677082   12.500000   18.100000  ...  396.225000   16.955000   25.000000\n",
              "max     88.976200  100.000000   27.740000  ...  396.900000   37.970000   50.000000\n",
              "\n",
              "[8 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "boston_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fy68VF8KMUfj",
        "outputId": "70f5ad10-8880-4ea6-c6e6-fa6dfbcaf641"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(506, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = boston_df.drop(\"MEDV\",axis=1)"
      ],
      "metadata": {
        "id": "4Ska-eFuMotb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGliMsJUM1ds",
        "outputId": "9cd08b32-710e-4fea-ff71-9f5be17c85d8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(506, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-9nR1BokM36F",
        "outputId": "9be57349-013b-4508-9402-300f95193237"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-81860870-04ae-42f5-8c35-a477e851ba5a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81860870-04ae-42f5-8c35-a477e851ba5a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-81860870-04ae-42f5-8c35-a477e851ba5a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-81860870-04ae-42f5-8c35-a477e851ba5a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      CRIM    ZN  INDUS  CHAS    NOX  ...  RAD    TAX  PTRATIO       B  LSTAT\n",
              "0  0.00632  18.0   2.31     0  0.538  ...    1  296.0     15.3  396.90   4.98\n",
              "1  0.02731   0.0   7.07     0  0.469  ...    2  242.0     17.8  396.90   9.14\n",
              "2  0.02729   0.0   7.07     0  0.469  ...    2  242.0     17.8  392.83   4.03\n",
              "3  0.03237   0.0   2.18     0  0.458  ...    3  222.0     18.7  394.63   2.94\n",
              "4  0.06905   0.0   2.18     0  0.458  ...    3  222.0     18.7  396.90   5.33\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = boston_df['MEDV']"
      ],
      "metadata": {
        "id": "fDZHwvaEM7cE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p94exDA4NBAN",
        "outputId": "10c615a0-e36d-4c61-e578-2a57e18d01a5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(506,)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7O3xRAfND5l",
        "outputId": "75d751df-5df1-4fd1-9285-8fdd8939763e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    24.0\n",
              "1    21.6\n",
              "2    34.7\n",
              "3    33.4\n",
              "4    36.2\n",
              "Name: MEDV, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "metadata": {
        "id": "CUq5urSbNTPH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAsT9uH-NWdD",
        "outputId": "7a8ab555-9a3e-4d70-a888-4fa3de64c66d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(404, 13) (404,) (102, 13) (102,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Using Only Input and Output Layers"
      ],
      "metadata": {
        "id": "zK7M55UhNqZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the Keras libraries and packages\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Initialising the ANN\n",
        "Regressor = Sequential()\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "#Regressor.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 10))\n",
        "\n",
        "# Adding the second hidden layer\n",
        "#Regressor.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "\n",
        "# Adding the output layer\n",
        "Regressor.add(Dense(units = 1))\n",
        "\n",
        "# Compiling the ANN\n",
        "Regressor.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics=[\"mean_squared_error\"])\n",
        "\n",
        "# Fitting the ANN to the Training set\n",
        "Regressor.fit(X_train, y_train, batch_size = 10, epochs = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYZbrO1ZNsRE",
        "outputId": "4bc931c1-96f7-4f30-a82c-82f59fa19bb9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 6834.3076 - mean_squared_error: 6834.3076\n",
            "Epoch 2/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 5727.6890 - mean_squared_error: 5727.6890\n",
            "Epoch 3/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 4879.1289 - mean_squared_error: 4879.1289\n",
            "Epoch 4/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 4108.4951 - mean_squared_error: 4108.4951\n",
            "Epoch 5/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 3427.5554 - mean_squared_error: 3427.5554\n",
            "Epoch 6/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 2853.1848 - mean_squared_error: 2853.1848\n",
            "Epoch 7/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 2343.3101 - mean_squared_error: 2343.3101\n",
            "Epoch 8/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 1919.2211 - mean_squared_error: 1919.2211\n",
            "Epoch 9/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 1572.7554 - mean_squared_error: 1572.7554\n",
            "Epoch 10/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 1259.7040 - mean_squared_error: 1259.7040\n",
            "Epoch 11/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 1020.9879 - mean_squared_error: 1020.9879\n",
            "Epoch 12/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 819.1414 - mean_squared_error: 819.1414\n",
            "Epoch 13/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 656.0471 - mean_squared_error: 656.0471\n",
            "Epoch 14/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 526.0601 - mean_squared_error: 526.0601\n",
            "Epoch 15/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 422.9236 - mean_squared_error: 422.9236\n",
            "Epoch 16/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 340.9393 - mean_squared_error: 340.9393\n",
            "Epoch 17/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 275.7763 - mean_squared_error: 275.7763\n",
            "Epoch 18/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 227.2242 - mean_squared_error: 227.2242\n",
            "Epoch 19/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 189.8276 - mean_squared_error: 189.8276\n",
            "Epoch 20/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 161.4126 - mean_squared_error: 161.4126\n",
            "Epoch 21/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 139.4276 - mean_squared_error: 139.4276\n",
            "Epoch 22/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 123.8648 - mean_squared_error: 123.8648\n",
            "Epoch 23/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 111.8822 - mean_squared_error: 111.8822\n",
            "Epoch 24/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 103.4779 - mean_squared_error: 103.4779\n",
            "Epoch 25/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 97.2549 - mean_squared_error: 97.2549\n",
            "Epoch 26/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 92.6454 - mean_squared_error: 92.6454\n",
            "Epoch 27/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 88.9071 - mean_squared_error: 88.9071\n",
            "Epoch 28/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 86.2020 - mean_squared_error: 86.2020\n",
            "Epoch 29/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 83.9274 - mean_squared_error: 83.9274\n",
            "Epoch 30/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 82.0560 - mean_squared_error: 82.0560\n",
            "Epoch 31/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 80.7980 - mean_squared_error: 80.7980\n",
            "Epoch 32/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 79.3267 - mean_squared_error: 79.3267\n",
            "Epoch 33/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 78.0903 - mean_squared_error: 78.0903\n",
            "Epoch 34/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 77.3576 - mean_squared_error: 77.3576\n",
            "Epoch 35/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 75.8891 - mean_squared_error: 75.8891\n",
            "Epoch 36/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 75.1282 - mean_squared_error: 75.1282\n",
            "Epoch 37/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 74.2603 - mean_squared_error: 74.2603\n",
            "Epoch 38/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 73.6520 - mean_squared_error: 73.6520\n",
            "Epoch 39/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 73.0164 - mean_squared_error: 73.0164\n",
            "Epoch 40/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 70.9191 - mean_squared_error: 70.9191\n",
            "Epoch 41/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 70.1699 - mean_squared_error: 70.1699\n",
            "Epoch 42/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 69.3070 - mean_squared_error: 69.3070\n",
            "Epoch 43/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 69.5928 - mean_squared_error: 69.5928\n",
            "Epoch 44/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 67.9207 - mean_squared_error: 67.9207\n",
            "Epoch 45/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 67.2012 - mean_squared_error: 67.2012\n",
            "Epoch 46/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 66.2262 - mean_squared_error: 66.2262\n",
            "Epoch 47/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 65.2258 - mean_squared_error: 65.2258\n",
            "Epoch 48/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 65.3059 - mean_squared_error: 65.3059\n",
            "Epoch 49/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 63.8435 - mean_squared_error: 63.8435\n",
            "Epoch 50/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 63.1837 - mean_squared_error: 63.1837\n",
            "Epoch 51/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 62.7432 - mean_squared_error: 62.7432\n",
            "Epoch 52/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 62.2952 - mean_squared_error: 62.2952\n",
            "Epoch 53/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 61.2966 - mean_squared_error: 61.2966\n",
            "Epoch 54/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 61.0349 - mean_squared_error: 61.0349\n",
            "Epoch 55/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 60.5171 - mean_squared_error: 60.5171\n",
            "Epoch 56/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 59.8556 - mean_squared_error: 59.8556\n",
            "Epoch 57/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 58.8500 - mean_squared_error: 58.8500\n",
            "Epoch 58/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 58.6305 - mean_squared_error: 58.6305\n",
            "Epoch 59/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 57.7076 - mean_squared_error: 57.7076\n",
            "Epoch 60/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 57.4295 - mean_squared_error: 57.4295\n",
            "Epoch 61/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 57.1489 - mean_squared_error: 57.1489\n",
            "Epoch 62/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 56.4041 - mean_squared_error: 56.4041\n",
            "Epoch 63/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 56.1195 - mean_squared_error: 56.1195\n",
            "Epoch 64/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 55.7558 - mean_squared_error: 55.7558\n",
            "Epoch 65/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 55.0436 - mean_squared_error: 55.0436\n",
            "Epoch 66/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 55.2753 - mean_squared_error: 55.2753\n",
            "Epoch 67/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 54.3929 - mean_squared_error: 54.3929\n",
            "Epoch 68/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 53.8919 - mean_squared_error: 53.8919\n",
            "Epoch 69/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 53.6208 - mean_squared_error: 53.6208\n",
            "Epoch 70/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 53.3362 - mean_squared_error: 53.3362\n",
            "Epoch 71/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 52.7730 - mean_squared_error: 52.7730\n",
            "Epoch 72/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 52.8995 - mean_squared_error: 52.8995\n",
            "Epoch 73/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 52.2759 - mean_squared_error: 52.2760\n",
            "Epoch 74/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 51.8902 - mean_squared_error: 51.8902\n",
            "Epoch 75/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 51.6897 - mean_squared_error: 51.6897\n",
            "Epoch 76/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 51.0848 - mean_squared_error: 51.0848\n",
            "Epoch 77/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 51.7982 - mean_squared_error: 51.7982\n",
            "Epoch 78/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 51.0714 - mean_squared_error: 51.0714\n",
            "Epoch 79/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 50.7757 - mean_squared_error: 50.7757\n",
            "Epoch 80/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 50.6464 - mean_squared_error: 50.6464\n",
            "Epoch 81/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 50.3805 - mean_squared_error: 50.3805\n",
            "Epoch 82/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 49.7952 - mean_squared_error: 49.7952\n",
            "Epoch 83/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 49.5483 - mean_squared_error: 49.5483\n",
            "Epoch 84/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 49.6977 - mean_squared_error: 49.6977\n",
            "Epoch 85/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 49.4314 - mean_squared_error: 49.4314\n",
            "Epoch 86/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 48.7265 - mean_squared_error: 48.7265\n",
            "Epoch 87/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 48.8218 - mean_squared_error: 48.8218\n",
            "Epoch 88/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 48.1814 - mean_squared_error: 48.1814\n",
            "Epoch 89/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 48.2706 - mean_squared_error: 48.2706\n",
            "Epoch 90/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 48.2066 - mean_squared_error: 48.2066\n",
            "Epoch 91/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 47.9700 - mean_squared_error: 47.9700\n",
            "Epoch 92/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 47.8173 - mean_squared_error: 47.8173\n",
            "Epoch 93/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 47.6844 - mean_squared_error: 47.6844\n",
            "Epoch 94/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 47.4542 - mean_squared_error: 47.4542\n",
            "Epoch 95/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 47.3204 - mean_squared_error: 47.3204\n",
            "Epoch 96/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 46.7458 - mean_squared_error: 46.7458\n",
            "Epoch 97/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 47.1683 - mean_squared_error: 47.1683\n",
            "Epoch 98/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 46.6833 - mean_squared_error: 46.6833\n",
            "Epoch 99/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 46.9283 - mean_squared_error: 46.9283\n",
            "Epoch 100/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 47.0141 - mean_squared_error: 47.0141\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6d6be7bed0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Part 3 - Making predictions and evaluating the model\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = Regressor.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import r2_score,mean_squared_error\n",
        "score = np.sqrt(mean_squared_error(y_test,y_pred))\n",
        "print (\"mean_squared_error: \",score)\n",
        "\n",
        "r2_score = r2_score(y_test,y_pred)\n",
        "print(\"r2_score: \",r2_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6o3dRmdnOZ36",
        "outputId": "25ca67b6-9de3-40ef-ce1a-e6879d7080bd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_squared_error:  7.636276469203553\n",
            "r2_score:  0.283877733800295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Using Input , One Hidden Layer and Output Layers"
      ],
      "metadata": {
        "id": "394k3Tk3P6NT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the Keras libraries and packages\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Initialising the ANN\n",
        "Regressor = Sequential()\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "Regressor.add(Dense(units = 100, kernel_initializer = 'uniform', activation = 'relu', input_dim = 13))\n",
        "\n",
        "# Adding the second hidden layer\n",
        "#Regressor.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "\n",
        "# Adding the output layer\n",
        "Regressor.add(Dense(units = 1))\n",
        "\n",
        "# Compiling the ANN\n",
        "Regressor.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics=[\"mean_squared_error\"])\n",
        "\n",
        "# Fitting the ANN to the Training set\n",
        "Regressor.fit(X_train, y_train, batch_size = 10, epochs = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzTlolEHP-oa",
        "outputId": "f7311f69-6281-48b7-e9e2-183e34c3261f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 241.4288 - mean_squared_error: 241.4288\n",
            "Epoch 2/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 67.6738 - mean_squared_error: 67.6738\n",
            "Epoch 3/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 61.6526 - mean_squared_error: 61.6526\n",
            "Epoch 4/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 59.0798 - mean_squared_error: 59.0798\n",
            "Epoch 5/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 52.9279 - mean_squared_error: 52.9279\n",
            "Epoch 6/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 51.5490 - mean_squared_error: 51.5490\n",
            "Epoch 7/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 47.1303 - mean_squared_error: 47.1303\n",
            "Epoch 8/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 43.2411 - mean_squared_error: 43.2411\n",
            "Epoch 9/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 43.2941 - mean_squared_error: 43.2941\n",
            "Epoch 10/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 48.6760 - mean_squared_error: 48.6760\n",
            "Epoch 11/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 40.4522 - mean_squared_error: 40.4522\n",
            "Epoch 12/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 39.0491 - mean_squared_error: 39.0491\n",
            "Epoch 13/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 37.1446 - mean_squared_error: 37.1446\n",
            "Epoch 14/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 34.4323 - mean_squared_error: 34.4323\n",
            "Epoch 15/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 34.8515 - mean_squared_error: 34.8515\n",
            "Epoch 16/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 33.9737 - mean_squared_error: 33.9737\n",
            "Epoch 17/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 35.7665 - mean_squared_error: 35.7665\n",
            "Epoch 18/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 34.7814 - mean_squared_error: 34.7814\n",
            "Epoch 19/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 31.3048 - mean_squared_error: 31.3048\n",
            "Epoch 20/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 33.5545 - mean_squared_error: 33.5545\n",
            "Epoch 21/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 31.1424 - mean_squared_error: 31.1424\n",
            "Epoch 22/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 32.9671 - mean_squared_error: 32.9671\n",
            "Epoch 23/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 34.9761 - mean_squared_error: 34.9761\n",
            "Epoch 24/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 30.0947 - mean_squared_error: 30.0947\n",
            "Epoch 25/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 29.5238 - mean_squared_error: 29.5238\n",
            "Epoch 26/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 29.0721 - mean_squared_error: 29.0721\n",
            "Epoch 27/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 31.6548 - mean_squared_error: 31.6548\n",
            "Epoch 28/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 32.4347 - mean_squared_error: 32.4347\n",
            "Epoch 29/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 30.2510 - mean_squared_error: 30.2510\n",
            "Epoch 30/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 32.9475 - mean_squared_error: 32.9475\n",
            "Epoch 31/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 29.6000 - mean_squared_error: 29.6000\n",
            "Epoch 32/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 28.8831 - mean_squared_error: 28.8831\n",
            "Epoch 33/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 31.6473 - mean_squared_error: 31.6473\n",
            "Epoch 34/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 32.0996 - mean_squared_error: 32.0996\n",
            "Epoch 35/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 28.1378 - mean_squared_error: 28.1378\n",
            "Epoch 36/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 26.6185 - mean_squared_error: 26.6185\n",
            "Epoch 37/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 26.6278 - mean_squared_error: 26.6278\n",
            "Epoch 38/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 30.2174 - mean_squared_error: 30.2174\n",
            "Epoch 39/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 29.3303 - mean_squared_error: 29.3303\n",
            "Epoch 40/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 24.5558 - mean_squared_error: 24.5558\n",
            "Epoch 41/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 24.8390 - mean_squared_error: 24.8390\n",
            "Epoch 42/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 28.4730 - mean_squared_error: 28.4730\n",
            "Epoch 43/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 24.4888 - mean_squared_error: 24.4888\n",
            "Epoch 44/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 23.9603 - mean_squared_error: 23.9603\n",
            "Epoch 45/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 24.7076 - mean_squared_error: 24.7076\n",
            "Epoch 46/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 24.3075 - mean_squared_error: 24.3075\n",
            "Epoch 47/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 26.2665 - mean_squared_error: 26.2665\n",
            "Epoch 48/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 24.5893 - mean_squared_error: 24.5893\n",
            "Epoch 49/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 21.8353 - mean_squared_error: 21.8353\n",
            "Epoch 50/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 21.9037 - mean_squared_error: 21.9037\n",
            "Epoch 51/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 21.7072 - mean_squared_error: 21.7072\n",
            "Epoch 52/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 22.1112 - mean_squared_error: 22.1112\n",
            "Epoch 53/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 19.9651 - mean_squared_error: 19.9651\n",
            "Epoch 54/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 21.2848 - mean_squared_error: 21.2848\n",
            "Epoch 55/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 22.2789 - mean_squared_error: 22.2789\n",
            "Epoch 56/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 19.8907 - mean_squared_error: 19.8907\n",
            "Epoch 57/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 19.5775 - mean_squared_error: 19.5775\n",
            "Epoch 58/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 18.8668 - mean_squared_error: 18.8668\n",
            "Epoch 59/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 21.9951 - mean_squared_error: 21.9951\n",
            "Epoch 60/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 19.5329 - mean_squared_error: 19.5329\n",
            "Epoch 61/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 21.1215 - mean_squared_error: 21.1215\n",
            "Epoch 62/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 22.7752 - mean_squared_error: 22.7752\n",
            "Epoch 63/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 24.5290 - mean_squared_error: 24.5290\n",
            "Epoch 64/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 21.4357 - mean_squared_error: 21.4357\n",
            "Epoch 65/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 19.9525 - mean_squared_error: 19.9525\n",
            "Epoch 66/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 18.4383 - mean_squared_error: 18.4383\n",
            "Epoch 67/100\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 20.3944 - mean_squared_error: 20.3944\n",
            "Epoch 68/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 19.2058 - mean_squared_error: 19.2058\n",
            "Epoch 69/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 18.1651 - mean_squared_error: 18.1651\n",
            "Epoch 70/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 18.2087 - mean_squared_error: 18.2087\n",
            "Epoch 71/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.7439 - mean_squared_error: 15.7439\n",
            "Epoch 72/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 17.1385 - mean_squared_error: 17.1385\n",
            "Epoch 73/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 18.2620 - mean_squared_error: 18.2620\n",
            "Epoch 74/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 19.2589 - mean_squared_error: 19.2589\n",
            "Epoch 75/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 16.7492 - mean_squared_error: 16.7492\n",
            "Epoch 76/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 19.0711 - mean_squared_error: 19.0711\n",
            "Epoch 77/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 18.7470 - mean_squared_error: 18.7470\n",
            "Epoch 78/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 18.4335 - mean_squared_error: 18.4335\n",
            "Epoch 79/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.5513 - mean_squared_error: 15.5513\n",
            "Epoch 80/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 16.4818 - mean_squared_error: 16.4818\n",
            "Epoch 81/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.6549 - mean_squared_error: 14.6549\n",
            "Epoch 82/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 16.4213 - mean_squared_error: 16.4213\n",
            "Epoch 83/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 20.3247 - mean_squared_error: 20.3247\n",
            "Epoch 84/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.8886 - mean_squared_error: 15.8886\n",
            "Epoch 85/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 16.5352 - mean_squared_error: 16.5351\n",
            "Epoch 86/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 16.1821 - mean_squared_error: 16.1821\n",
            "Epoch 87/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 18.0565 - mean_squared_error: 18.0565\n",
            "Epoch 88/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.8442 - mean_squared_error: 15.8442\n",
            "Epoch 89/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.8658 - mean_squared_error: 14.8658\n",
            "Epoch 90/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 16.4359 - mean_squared_error: 16.4359\n",
            "Epoch 91/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 16.0951 - mean_squared_error: 16.0951\n",
            "Epoch 92/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.2255 - mean_squared_error: 14.2255\n",
            "Epoch 93/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.9659 - mean_squared_error: 14.9659\n",
            "Epoch 94/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.4995 - mean_squared_error: 14.4995\n",
            "Epoch 95/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.5762 - mean_squared_error: 14.5762\n",
            "Epoch 96/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 16.7248 - mean_squared_error: 16.7248\n",
            "Epoch 97/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.1666 - mean_squared_error: 14.1666\n",
            "Epoch 98/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 16.2363 - mean_squared_error: 16.2363\n",
            "Epoch 99/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.0849 - mean_squared_error: 15.0849\n",
            "Epoch 100/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 13.5321 - mean_squared_error: 13.5321\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6d6bc0e690>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Part 3 - Making predictions and evaluating the model\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = Regressor.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import r2_score,mean_squared_error\n",
        "score = np.sqrt(mean_squared_error(y_test,y_pred))\n",
        "print (\"mean_squared_error: \",score)\n",
        "\n",
        "r2_score = r2_score(y_test,y_pred)\n",
        "print(\"r2_score: \",r2_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZducUhlPVs-",
        "outputId": "6400b8eb-cf7a-40fb-8549-7ff450d6da48"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_squared_error:  5.584557991923298\n",
            "r2_score:  0.6169975953800758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Using Input , Two Hidden Layers and Output Layers"
      ],
      "metadata": {
        "id": "V8_S5669QpS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the Keras libraries and packages\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Initialising the ANN\n",
        "Regressor = Sequential()\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "Regressor.add(Dense(units = 100, kernel_initializer = 'uniform', activation = 'relu', input_dim = 13))\n",
        "\n",
        "# Adding the second hidden layer\n",
        "Regressor.add(Dense(units = 50, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "\n",
        "# Adding the output layer\n",
        "Regressor.add(Dense(units = 1))\n",
        "\n",
        "# Compiling the ANN\n",
        "Regressor.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics=[\"mean_squared_error\"])\n",
        "\n",
        "# Fitting the ANN to the Training set\n",
        "Regressor.fit(X_train, y_train, batch_size = 10, epochs = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46LVjfKdQqh-",
        "outputId": "fedba56d-fc5d-43b1-86e2-9999525619c2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 141.6764 - mean_squared_error: 141.6764\n",
            "Epoch 2/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 60.0780 - mean_squared_error: 60.0780\n",
            "Epoch 3/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 56.9051 - mean_squared_error: 56.9051\n",
            "Epoch 4/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 52.5454 - mean_squared_error: 52.5454\n",
            "Epoch 5/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 50.9160 - mean_squared_error: 50.9160\n",
            "Epoch 6/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 49.2632 - mean_squared_error: 49.2632\n",
            "Epoch 7/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 47.8584 - mean_squared_error: 47.8584\n",
            "Epoch 8/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 45.1654 - mean_squared_error: 45.1654\n",
            "Epoch 9/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 42.8425 - mean_squared_error: 42.8425\n",
            "Epoch 10/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 38.9575 - mean_squared_error: 38.9575\n",
            "Epoch 11/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 35.0408 - mean_squared_error: 35.0408\n",
            "Epoch 12/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 38.2684 - mean_squared_error: 38.2684\n",
            "Epoch 13/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 34.9352 - mean_squared_error: 34.9352\n",
            "Epoch 14/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 31.3309 - mean_squared_error: 31.3309\n",
            "Epoch 15/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 30.7143 - mean_squared_error: 30.7143\n",
            "Epoch 16/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 33.8210 - mean_squared_error: 33.8210\n",
            "Epoch 17/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 34.5967 - mean_squared_error: 34.5967\n",
            "Epoch 18/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 27.9533 - mean_squared_error: 27.9533\n",
            "Epoch 19/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 28.3831 - mean_squared_error: 28.3831\n",
            "Epoch 20/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 25.3109 - mean_squared_error: 25.3109\n",
            "Epoch 21/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 25.1596 - mean_squared_error: 25.1596\n",
            "Epoch 22/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 25.0487 - mean_squared_error: 25.0487\n",
            "Epoch 23/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 24.4761 - mean_squared_error: 24.4761\n",
            "Epoch 24/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 27.7279 - mean_squared_error: 27.7279\n",
            "Epoch 25/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 26.3222 - mean_squared_error: 26.3222\n",
            "Epoch 26/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 23.4023 - mean_squared_error: 23.4023\n",
            "Epoch 27/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 21.2861 - mean_squared_error: 21.2861\n",
            "Epoch 28/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 20.4341 - mean_squared_error: 20.4341\n",
            "Epoch 29/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 22.4886 - mean_squared_error: 22.4886\n",
            "Epoch 30/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 21.9624 - mean_squared_error: 21.9624\n",
            "Epoch 31/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 20.6310 - mean_squared_error: 20.6310\n",
            "Epoch 32/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 19.0298 - mean_squared_error: 19.0298\n",
            "Epoch 33/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 22.9463 - mean_squared_error: 22.9463\n",
            "Epoch 34/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 18.7525 - mean_squared_error: 18.7525\n",
            "Epoch 35/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 21.8251 - mean_squared_error: 21.8251\n",
            "Epoch 36/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 21.7533 - mean_squared_error: 21.7533\n",
            "Epoch 37/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 20.9722 - mean_squared_error: 20.9722\n",
            "Epoch 38/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 19.6850 - mean_squared_error: 19.6850\n",
            "Epoch 39/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 20.5872 - mean_squared_error: 20.5872\n",
            "Epoch 40/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 20.3560 - mean_squared_error: 20.3560\n",
            "Epoch 41/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 19.3593 - mean_squared_error: 19.3593\n",
            "Epoch 42/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 19.1464 - mean_squared_error: 19.1464\n",
            "Epoch 43/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 23.4815 - mean_squared_error: 23.4815\n",
            "Epoch 44/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 16.5212 - mean_squared_error: 16.5212\n",
            "Epoch 45/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 16.1752 - mean_squared_error: 16.1752\n",
            "Epoch 46/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.8946 - mean_squared_error: 15.8946\n",
            "Epoch 47/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.9194 - mean_squared_error: 15.9194\n",
            "Epoch 48/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.9678 - mean_squared_error: 15.9678\n",
            "Epoch 49/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.8904 - mean_squared_error: 15.8904\n",
            "Epoch 50/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.6591 - mean_squared_error: 14.6591\n",
            "Epoch 51/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 17.5966 - mean_squared_error: 17.5966\n",
            "Epoch 52/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.0016 - mean_squared_error: 15.0016\n",
            "Epoch 53/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 17.6309 - mean_squared_error: 17.6309\n",
            "Epoch 54/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 16.3395 - mean_squared_error: 16.3395\n",
            "Epoch 55/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.7687 - mean_squared_error: 15.7687\n",
            "Epoch 56/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 19.4503 - mean_squared_error: 19.4503\n",
            "Epoch 57/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.7922 - mean_squared_error: 14.7922\n",
            "Epoch 58/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 17.7902 - mean_squared_error: 17.7902\n",
            "Epoch 59/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.1726 - mean_squared_error: 14.1726\n",
            "Epoch 60/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.8752 - mean_squared_error: 15.8752\n",
            "Epoch 61/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 18.9781 - mean_squared_error: 18.9781\n",
            "Epoch 62/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 18.6224 - mean_squared_error: 18.6224\n",
            "Epoch 63/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 16.5315 - mean_squared_error: 16.5315\n",
            "Epoch 64/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.2336 - mean_squared_error: 14.2336\n",
            "Epoch 65/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 16.3257 - mean_squared_error: 16.3257\n",
            "Epoch 66/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 18.5730 - mean_squared_error: 18.5730\n",
            "Epoch 67/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 17.7785 - mean_squared_error: 17.7785\n",
            "Epoch 68/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.8500 - mean_squared_error: 15.8500\n",
            "Epoch 69/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.3104 - mean_squared_error: 14.3104\n",
            "Epoch 70/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 16.1490 - mean_squared_error: 16.1490\n",
            "Epoch 71/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.9553 - mean_squared_error: 14.9553\n",
            "Epoch 72/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 16.1671 - mean_squared_error: 16.1671\n",
            "Epoch 73/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 16.2957 - mean_squared_error: 16.2957\n",
            "Epoch 74/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 16.8842 - mean_squared_error: 16.8842\n",
            "Epoch 75/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.2174 - mean_squared_error: 14.2174\n",
            "Epoch 76/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 12.8198 - mean_squared_error: 12.8198\n",
            "Epoch 77/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 19.8307 - mean_squared_error: 19.8307\n",
            "Epoch 78/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.5392 - mean_squared_error: 14.5392\n",
            "Epoch 79/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.9523 - mean_squared_error: 14.9523\n",
            "Epoch 80/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.1661 - mean_squared_error: 15.1661\n",
            "Epoch 81/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.3021 - mean_squared_error: 14.3021\n",
            "Epoch 82/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 13.8960 - mean_squared_error: 13.8960\n",
            "Epoch 83/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.1498 - mean_squared_error: 14.1498\n",
            "Epoch 84/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.4176 - mean_squared_error: 15.4176\n",
            "Epoch 85/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 15.0551 - mean_squared_error: 15.0551\n",
            "Epoch 86/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 16.9365 - mean_squared_error: 16.9365\n",
            "Epoch 87/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.9860 - mean_squared_error: 15.9860\n",
            "Epoch 88/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 13.5173 - mean_squared_error: 13.5173\n",
            "Epoch 89/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 18.0388 - mean_squared_error: 18.0388\n",
            "Epoch 90/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 12.6288 - mean_squared_error: 12.6288\n",
            "Epoch 91/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.0974 - mean_squared_error: 14.0974\n",
            "Epoch 92/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.6154 - mean_squared_error: 15.6154\n",
            "Epoch 93/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.6403 - mean_squared_error: 14.6403\n",
            "Epoch 94/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 13.7772 - mean_squared_error: 13.7772\n",
            "Epoch 95/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.0675 - mean_squared_error: 14.0675\n",
            "Epoch 96/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.8979 - mean_squared_error: 14.8979\n",
            "Epoch 97/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 12.3840 - mean_squared_error: 12.3840\n",
            "Epoch 98/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 12.3682 - mean_squared_error: 12.3682\n",
            "Epoch 99/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 16.1289 - mean_squared_error: 16.1289\n",
            "Epoch 100/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 13.4579 - mean_squared_error: 13.4579\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6d67c44f50>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Part 3 - Making predictions and evaluating the model\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = Regressor.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import r2_score,mean_squared_error\n",
        "score = np.sqrt(mean_squared_error(y_test,y_pred))\n",
        "print (\"mean_squared_error: \",score)\n",
        "\n",
        "r2_score = r2_score(y_test,y_pred)\n",
        "print(\"r2_score: \",r2_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaQ36DRiQszb",
        "outputId": "40fbd172-5537-405a-d5bc-3cba64ac0242"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_squared_error:  5.152435765782038\n",
            "r2_score:  0.673976381883861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Using Input , Two Hidden Layers and Output Layers with BatchNormalization and Dropout"
      ],
      "metadata": {
        "id": "BsSFpZS9RaHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the Keras libraries and packages\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import BatchNormalization,Dropout\n",
        "\n",
        "# Initialising the ANN\n",
        "Regressor = Sequential()\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "Regressor.add(Dense(units = 100, kernel_initializer = 'uniform', activation = 'relu', input_dim = 13))\n",
        "Regressor.add(BatchNormalization())\n",
        "Regressor.add(Dropout(0.5))\n",
        "\n",
        "# Adding the second hidden layer\n",
        "Regressor.add(Dense(units = 50, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "Regressor.add(BatchNormalization())\n",
        "Regressor.add(Dropout(0.5))\n",
        "\n",
        "# Adding the output layer\n",
        "Regressor.add(Dense(units = 1))\n",
        "Regressor.add(BatchNormalization())\n",
        "Regressor.add(Dropout(0.5))\n",
        "\n",
        "# Compiling the ANN\n",
        "Regressor.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics=[\"mean_squared_error\"])\n",
        "\n",
        "# Fitting the ANN to the Training set\n",
        "Regressor.fit(X_train, y_train, batch_size = 10, epochs = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkyFWrPpRmHN",
        "outputId": "3d5be8af-5cd0-406a-e7fc-e32ae86a6b94"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "41/41 [==============================] - 1s 2ms/step - loss: 588.9186 - mean_squared_error: 588.9186\n",
            "Epoch 2/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 586.8601 - mean_squared_error: 586.8601\n",
            "Epoch 3/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 581.7166 - mean_squared_error: 581.7166\n",
            "Epoch 4/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 583.2162 - mean_squared_error: 583.2162\n",
            "Epoch 5/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 579.1647 - mean_squared_error: 579.1647\n",
            "Epoch 6/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 580.1809 - mean_squared_error: 580.1809\n",
            "Epoch 7/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 579.9646 - mean_squared_error: 579.9646\n",
            "Epoch 8/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 580.2693 - mean_squared_error: 580.2693\n",
            "Epoch 9/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 573.1145 - mean_squared_error: 573.1145\n",
            "Epoch 10/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 566.8121 - mean_squared_error: 566.8121\n",
            "Epoch 11/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 568.6734 - mean_squared_error: 568.6734\n",
            "Epoch 12/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 572.1342 - mean_squared_error: 572.1342\n",
            "Epoch 13/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 562.6703 - mean_squared_error: 562.6703\n",
            "Epoch 14/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 572.2705 - mean_squared_error: 572.2705\n",
            "Epoch 15/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 553.6656 - mean_squared_error: 553.6656\n",
            "Epoch 16/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 558.8823 - mean_squared_error: 558.8823\n",
            "Epoch 17/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 560.1382 - mean_squared_error: 560.1382\n",
            "Epoch 18/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 552.4329 - mean_squared_error: 552.4329\n",
            "Epoch 19/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 561.1119 - mean_squared_error: 561.1119\n",
            "Epoch 20/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 551.4814 - mean_squared_error: 551.4814\n",
            "Epoch 21/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 559.3362 - mean_squared_error: 559.3362\n",
            "Epoch 22/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 556.0011 - mean_squared_error: 556.0011\n",
            "Epoch 23/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 546.4875 - mean_squared_error: 546.4875\n",
            "Epoch 24/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 550.7434 - mean_squared_error: 550.7434\n",
            "Epoch 25/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 549.6703 - mean_squared_error: 549.6702\n",
            "Epoch 26/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 539.7083 - mean_squared_error: 539.7083\n",
            "Epoch 27/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 529.7259 - mean_squared_error: 529.7259\n",
            "Epoch 28/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 534.2448 - mean_squared_error: 534.2448\n",
            "Epoch 29/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 535.1205 - mean_squared_error: 535.1205\n",
            "Epoch 30/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 536.6934 - mean_squared_error: 536.6934\n",
            "Epoch 31/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 523.3524 - mean_squared_error: 523.3524\n",
            "Epoch 32/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 528.4406 - mean_squared_error: 528.4406\n",
            "Epoch 33/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 524.7230 - mean_squared_error: 524.7230\n",
            "Epoch 34/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 531.6105 - mean_squared_error: 531.6105\n",
            "Epoch 35/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 525.8018 - mean_squared_error: 525.8018\n",
            "Epoch 36/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 521.8493 - mean_squared_error: 521.8492\n",
            "Epoch 37/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 519.8943 - mean_squared_error: 519.8943\n",
            "Epoch 38/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 522.5966 - mean_squared_error: 522.5966\n",
            "Epoch 39/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 524.6560 - mean_squared_error: 524.6560\n",
            "Epoch 40/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 518.0597 - mean_squared_error: 518.0597\n",
            "Epoch 41/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 519.5568 - mean_squared_error: 519.5568\n",
            "Epoch 42/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 515.7311 - mean_squared_error: 515.7311\n",
            "Epoch 43/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 515.5162 - mean_squared_error: 515.5162\n",
            "Epoch 44/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 515.8112 - mean_squared_error: 515.8112\n",
            "Epoch 45/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 513.9366 - mean_squared_error: 513.9366\n",
            "Epoch 46/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 507.2871 - mean_squared_error: 507.2871\n",
            "Epoch 47/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 504.8183 - mean_squared_error: 504.8183\n",
            "Epoch 48/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 509.1965 - mean_squared_error: 509.1965\n",
            "Epoch 49/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 498.7017 - mean_squared_error: 498.7017\n",
            "Epoch 50/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 515.6724 - mean_squared_error: 515.6724\n",
            "Epoch 51/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 505.4878 - mean_squared_error: 505.4878\n",
            "Epoch 52/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 501.2553 - mean_squared_error: 501.2554\n",
            "Epoch 53/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 504.5486 - mean_squared_error: 504.5486\n",
            "Epoch 54/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 492.4012 - mean_squared_error: 492.4012\n",
            "Epoch 55/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 499.8569 - mean_squared_error: 499.8569\n",
            "Epoch 56/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 489.3428 - mean_squared_error: 489.3428\n",
            "Epoch 57/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 502.2285 - mean_squared_error: 502.2285\n",
            "Epoch 58/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 495.5657 - mean_squared_error: 495.5657\n",
            "Epoch 59/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 487.2235 - mean_squared_error: 487.2235\n",
            "Epoch 60/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 488.0386 - mean_squared_error: 488.0386\n",
            "Epoch 61/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 486.3645 - mean_squared_error: 486.3645\n",
            "Epoch 62/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 476.4771 - mean_squared_error: 476.4771\n",
            "Epoch 63/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 490.9925 - mean_squared_error: 490.9925\n",
            "Epoch 64/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 466.9391 - mean_squared_error: 466.9391\n",
            "Epoch 65/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 484.2789 - mean_squared_error: 484.2789\n",
            "Epoch 66/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 485.4956 - mean_squared_error: 485.4956\n",
            "Epoch 67/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 473.8536 - mean_squared_error: 473.8536\n",
            "Epoch 68/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 475.5677 - mean_squared_error: 475.5677\n",
            "Epoch 69/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 484.2062 - mean_squared_error: 484.2062\n",
            "Epoch 70/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 476.6973 - mean_squared_error: 476.6973\n",
            "Epoch 71/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 465.3674 - mean_squared_error: 465.3674\n",
            "Epoch 72/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 472.7289 - mean_squared_error: 472.7289\n",
            "Epoch 73/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 476.1129 - mean_squared_error: 476.1129\n",
            "Epoch 74/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 469.2164 - mean_squared_error: 469.2164\n",
            "Epoch 75/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 475.2477 - mean_squared_error: 475.2477\n",
            "Epoch 76/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 480.1360 - mean_squared_error: 480.1360\n",
            "Epoch 77/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 463.7714 - mean_squared_error: 463.7714\n",
            "Epoch 78/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 467.5530 - mean_squared_error: 467.5530\n",
            "Epoch 79/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 449.0000 - mean_squared_error: 449.0000\n",
            "Epoch 80/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 458.1269 - mean_squared_error: 458.1269\n",
            "Epoch 81/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 469.7955 - mean_squared_error: 469.7955\n",
            "Epoch 82/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 472.5508 - mean_squared_error: 472.5508\n",
            "Epoch 83/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 477.2366 - mean_squared_error: 477.2366\n",
            "Epoch 84/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 434.1176 - mean_squared_error: 434.1176\n",
            "Epoch 85/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 470.1566 - mean_squared_error: 470.1566\n",
            "Epoch 86/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 453.9336 - mean_squared_error: 453.9336\n",
            "Epoch 87/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 450.6700 - mean_squared_error: 450.6700\n",
            "Epoch 88/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 466.5130 - mean_squared_error: 466.5130\n",
            "Epoch 89/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 448.9621 - mean_squared_error: 448.9621\n",
            "Epoch 90/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 452.3828 - mean_squared_error: 452.3828\n",
            "Epoch 91/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 447.5292 - mean_squared_error: 447.5292\n",
            "Epoch 92/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 458.0744 - mean_squared_error: 458.0744\n",
            "Epoch 93/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 444.3112 - mean_squared_error: 444.3112\n",
            "Epoch 94/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 440.2763 - mean_squared_error: 440.2763\n",
            "Epoch 95/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 460.6328 - mean_squared_error: 460.6328\n",
            "Epoch 96/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 440.5702 - mean_squared_error: 440.5702\n",
            "Epoch 97/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 441.9777 - mean_squared_error: 441.9777\n",
            "Epoch 98/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 439.9359 - mean_squared_error: 439.9359\n",
            "Epoch 99/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 444.0938 - mean_squared_error: 444.0938\n",
            "Epoch 100/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 440.7134 - mean_squared_error: 440.7134\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6d672bc190>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Part 3 - Making predictions and evaluating the model\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = Regressor.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import r2_score,mean_squared_error\n",
        "score = np.sqrt(mean_squared_error(y_test,y_pred))\n",
        "print (\"mean_squared_error: \",score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqR4NIdOR7T-",
        "outputId": "b5b3d307-4176-4df0-a883-7108edb4c6a0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_squared_error:  18.842764630618387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Early Stopping"
      ],
      "metadata": {
        "id": "1nrOvDbRSjiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Improving the ANN\n",
        "# Dropout Regularization to reduce overfitting if needed\n",
        "\n",
        "# Tuning the ANN\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "def build_regressor(optimizer):\n",
        "    regressor = Sequential()\n",
        "    regressor.add(Dense(units = 100, kernel_initializer = 'uniform', activation = 'relu', input_dim = 13))\n",
        "    regressor.add(Dense(units = 50, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "    regressor.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "    regressor.compile(optimizer = optimizer, loss = 'mean_squared_error', metrics = ['mean_squared_error'])\n",
        "    return regressor"
      ],
      "metadata": {
        "id": "GFJtt5IZSj3U"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# simple early stopping\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)"
      ],
      "metadata": {
        "id": "e5ReVHIXS_PC"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = KerasRegressor(build_fn = build_regressor)\n",
        "parameters = {'batch_size': [25, 32],\n",
        "              'epochs': [100, 500],\n",
        "              'optimizer': ['adam', 'rmsprop']}\n",
        "grid_search = GridSearchCV(estimator = classifier,\n",
        "                           param_grid = parameters,                           \n",
        "                           cv = 10)\n",
        "grid_search = grid_search.fit(X_train, y_train,validation_data=(X_test, y_test),callbacks=[es])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Wr59EG6S8qS",
        "outputId": "383a744c-d35d-4502-d655-c141cc3428fb"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 15ms/step - loss: 564.1263 - mean_squared_error: 564.1263 - val_loss: 531.7135 - val_mean_squared_error: 531.7136\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 557.5565 - mean_squared_error: 557.5565 - val_loss: 531.7004 - val_mean_squared_error: 531.7004\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 504.9748 - mean_squared_error: 504.9748\n",
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 13ms/step - loss: 566.4459 - mean_squared_error: 566.4459 - val_loss: 531.7028 - val_mean_squared_error: 531.7028\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 564.1203 - mean_squared_error: 564.1203 - val_loss: 531.7003 - val_mean_squared_error: 531.7003\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 446.8379 - mean_squared_error: 446.8379\n",
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 15ms/step - loss: 553.4133 - mean_squared_error: 553.4133 - val_loss: 531.7170 - val_mean_squared_error: 531.7170\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 547.5261 - mean_squared_error: 547.5261 - val_loss: 531.7003 - val_mean_squared_error: 531.7003\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 593.7882 - mean_squared_error: 593.7882\n",
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 13ms/step - loss: 563.3086 - mean_squared_error: 563.3086 - val_loss: 531.7065 - val_mean_squared_error: 531.7065\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 558.7170 - mean_squared_error: 558.7170 - val_loss: 531.7003 - val_mean_squared_error: 531.7003\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 494.6862 - mean_squared_error: 494.6862\n",
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 14ms/step - loss: 559.1455 - mean_squared_error: 559.1455 - val_loss: 531.7338 - val_mean_squared_error: 531.7338\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 551.9694 - mean_squared_error: 551.9694 - val_loss: 531.7006 - val_mean_squared_error: 531.7006\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 554.5749 - mean_squared_error: 554.5749\n",
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 14ms/step - loss: 552.9547 - mean_squared_error: 552.9547 - val_loss: 531.7095 - val_mean_squared_error: 531.7095\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 549.8343 - mean_squared_error: 549.8342 - val_loss: 531.7005 - val_mean_squared_error: 531.7005\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 573.9315 - mean_squared_error: 573.9315\n",
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 14ms/step - loss: 550.5047 - mean_squared_error: 550.5047 - val_loss: 531.7044 - val_mean_squared_error: 531.7044\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 548.2114 - mean_squared_error: 548.2114 - val_loss: 531.7003 - val_mean_squared_error: 531.7003\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 588.6840 - mean_squared_error: 588.6840\n",
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 14ms/step - loss: 540.2207 - mean_squared_error: 540.2207 - val_loss: 531.7054 - val_mean_squared_error: 531.7054\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 536.7039 - mean_squared_error: 536.7039 - val_loss: 531.7003 - val_mean_squared_error: 531.7003\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 693.4011 - mean_squared_error: 693.4011\n",
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 13ms/step - loss: 556.8174 - mean_squared_error: 556.8174 - val_loss: 531.7156 - val_mean_squared_error: 531.7156\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 552.3621 - mean_squared_error: 552.3621 - val_loss: 531.7006 - val_mean_squared_error: 531.7006\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 550.9531 - mean_squared_error: 550.9531\n",
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 14ms/step - loss: 560.0467 - mean_squared_error: 560.0467 - val_loss: 531.7042 - val_mean_squared_error: 531.7041\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 555.2579 - mean_squared_error: 555.2579 - val_loss: 531.7003 - val_mean_squared_error: 531.7003\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 524.5565 - mean_squared_error: 524.5565\n",
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 14ms/step - loss: 560.5076 - mean_squared_error: 560.5076 - val_loss: 531.7472 - val_mean_squared_error: 531.7472\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 557.5878 - mean_squared_error: 557.5878 - val_loss: 531.7083 - val_mean_squared_error: 531.7083\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 504.9867 - mean_squared_error: 504.9867\n",
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 13ms/step - loss: 566.7024 - mean_squared_error: 566.7024 - val_loss: 531.7268 - val_mean_squared_error: 531.7268\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 564.1353 - mean_squared_error: 564.1353 - val_loss: 531.7026 - val_mean_squared_error: 531.7026\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 446.8416 - mean_squared_error: 446.8416\n",
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 14ms/step - loss: 549.2625 - mean_squared_error: 549.2625 - val_loss: 531.7416 - val_mean_squared_error: 531.7416\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 547.5508 - mean_squared_error: 547.5508 - val_loss: 531.7088 - val_mean_squared_error: 531.7088\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 593.8024 - mean_squared_error: 593.8024\n",
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 14ms/step - loss: 560.4639 - mean_squared_error: 560.4639 - val_loss: 531.7171 - val_mean_squared_error: 531.7171\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 558.7255 - mean_squared_error: 558.7255 - val_loss: 531.7017 - val_mean_squared_error: 531.7017\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 494.6883 - mean_squared_error: 494.6883\n",
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 13ms/step - loss: 556.1753 - mean_squared_error: 556.1753 - val_loss: 531.7669 - val_mean_squared_error: 531.7669\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 552.0005 - mean_squared_error: 552.0005 - val_loss: 531.7100 - val_mean_squared_error: 531.7100\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 554.5863 - mean_squared_error: 554.5863\n",
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 14ms/step - loss: 551.5847 - mean_squared_error: 551.5847 - val_loss: 531.7202 - val_mean_squared_error: 531.7202\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 549.8441 - mean_squared_error: 549.8441 - val_loss: 531.7036 - val_mean_squared_error: 531.7036\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 573.9363 - mean_squared_error: 573.9363\n",
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 12ms/step - loss: 550.6904 - mean_squared_error: 550.6904 - val_loss: 531.7446 - val_mean_squared_error: 531.7446\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 548.2372 - mean_squared_error: 548.2372 - val_loss: 531.7095 - val_mean_squared_error: 531.7095\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 588.6953 - mean_squared_error: 588.6953\n",
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 14ms/step - loss: 540.2633 - mean_squared_error: 540.2633 - val_loss: 531.7687 - val_mean_squared_error: 531.7687\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 536.7457 - mean_squared_error: 536.7457 - val_loss: 531.7122 - val_mean_squared_error: 531.7122\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 693.4197 - mean_squared_error: 693.4197\n",
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 13ms/step - loss: 555.0414 - mean_squared_error: 555.0414 - val_loss: 531.7430 - val_mean_squared_error: 531.7430\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 552.3785 - mean_squared_error: 552.3785 - val_loss: 531.7085 - val_mean_squared_error: 531.7085\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 550.9594 - mean_squared_error: 550.9594\n",
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 13ms/step - loss: 557.4259 - mean_squared_error: 557.4259 - val_loss: 531.7263 - val_mean_squared_error: 531.7263\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 555.2729 - mean_squared_error: 555.2729 - val_loss: 531.7048 - val_mean_squared_error: 531.7048\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 524.5634 - mean_squared_error: 524.5634\n",
            "Epoch 1/500\n",
            "15/15 [==============================] - 1s 13ms/step - loss: 561.0636 - mean_squared_error: 561.0636 - val_loss: 531.7123 - val_mean_squared_error: 531.7123\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 557.5574 - mean_squared_error: 557.5574 - val_loss: 531.7009 - val_mean_squared_error: 531.7009\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 504.9752 - mean_squared_error: 504.9752\n",
            "Epoch 1/500\n",
            "15/15 [==============================] - 1s 13ms/step - loss: 569.4976 - mean_squared_error: 569.4976 - val_loss: 531.7158 - val_mean_squared_error: 531.7158\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 564.1235 - mean_squared_error: 564.1235 - val_loss: 531.7003 - val_mean_squared_error: 531.7003\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 446.8380 - mean_squared_error: 446.8380\n",
            "Epoch 1/500\n",
            "15/15 [==============================] - 1s 14ms/step - loss: 553.5347 - mean_squared_error: 553.5347 - val_loss: 531.7704 - val_mean_squared_error: 531.7704\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 547.5424 - mean_squared_error: 547.5424 - val_loss: 531.7020 - val_mean_squared_error: 531.7020\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 593.7911 - mean_squared_error: 593.7911\n",
            "Epoch 1/500\n",
            "15/15 [==============================] - 1s 14ms/step - loss: 563.3131 - mean_squared_error: 563.3131 - val_loss: 531.7086 - val_mean_squared_error: 531.7086\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 558.7176 - mean_squared_error: 558.7176 - val_loss: 531.7003 - val_mean_squared_error: 531.7003\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 494.6862 - mean_squared_error: 494.6862\n",
            "Epoch 1/500\n",
            "15/15 [==============================] - 1s 13ms/step - loss: 555.5444 - mean_squared_error: 555.5444 - val_loss: 531.7037 - val_mean_squared_error: 531.7037\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 551.9590 - mean_squared_error: 551.9590 - val_loss: 531.7003 - val_mean_squared_error: 531.7003\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 554.5743 - mean_squared_error: 554.5743\n",
            "Epoch 1/500\n",
            "15/15 [==============================] - 1s 14ms/step - loss: 555.5672 - mean_squared_error: 555.5672 - val_loss: 531.7553 - val_mean_squared_error: 531.7553\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 549.8486 - mean_squared_error: 549.8486 - val_loss: 531.7012 - val_mean_squared_error: 531.7012\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 573.9327 - mean_squared_error: 573.9328\n",
            "Epoch 1/500\n",
            "15/15 [==============================] - 1s 13ms/step - loss: 553.1142 - mean_squared_error: 553.1142 - val_loss: 531.7146 - val_mean_squared_error: 531.7146\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 548.2136 - mean_squared_error: 548.2136 - val_loss: 531.7004 - val_mean_squared_error: 531.7004\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 588.6840 - mean_squared_error: 588.6840\n",
            "Epoch 1/500\n",
            "15/15 [==============================] - 1s 14ms/step - loss: 540.6151 - mean_squared_error: 540.6150 - val_loss: 531.7183 - val_mean_squared_error: 531.7183\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 536.7091 - mean_squared_error: 536.7091 - val_loss: 531.7005 - val_mean_squared_error: 531.7006\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 693.4017 - mean_squared_error: 693.4017\n",
            "Epoch 1/500\n",
            "15/15 [==============================] - 1s 14ms/step - loss: 557.5303 - mean_squared_error: 557.5303 - val_loss: 531.7213 - val_mean_squared_error: 531.7213\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 552.3625 - mean_squared_error: 552.3625 - val_loss: 531.7007 - val_mean_squared_error: 531.7007\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 550.9532 - mean_squared_error: 550.9532\n",
            "Epoch 1/500\n",
            "15/15 [==============================] - 1s 13ms/step - loss: 559.8289 - mean_squared_error: 559.8289 - val_loss: 531.7106 - val_mean_squared_error: 531.7106\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 555.2596 - mean_squared_error: 555.2596 - val_loss: 531.7004 - val_mean_squared_error: 531.7004\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 524.5568 - mean_squared_error: 524.5568\n",
            "Epoch 1/500\n",
            "15/15 [==============================] - 1s 13ms/step - loss: 560.2415 - mean_squared_error: 560.2415 - val_loss: 531.7147 - val_mean_squared_error: 531.7147\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 557.5607 - mean_squared_error: 557.5607 - val_loss: 531.7026 - val_mean_squared_error: 531.7026\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 504.9768 - mean_squared_error: 504.9768\n",
            "Epoch 1/500\n",
            "15/15 [==============================] - 1s 14ms/step - loss: 566.9395 - mean_squared_error: 566.9395 - val_loss: 531.7557 - val_mean_squared_error: 531.7557\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 564.1597 - mean_squared_error: 564.1597 - val_loss: 531.7107 - val_mean_squared_error: 531.7107\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 446.8519 - mean_squared_error: 446.8519\n",
            "Epoch 1/500\n",
            "15/15 [==============================] - 1s 13ms/step - loss: 551.5605 - mean_squared_error: 551.5605 - val_loss: 531.7664 - val_mean_squared_error: 531.7664\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 547.5500 - mean_squared_error: 547.5500 - val_loss: 531.7062 - val_mean_squared_error: 531.7062\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 593.7972 - mean_squared_error: 593.7972\n",
            "Epoch 1/500\n",
            "15/15 [==============================] - 1s 13ms/step - loss: 561.1540 - mean_squared_error: 561.1540 - val_loss: 531.7291 - val_mean_squared_error: 531.7291\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 558.7307 - mean_squared_error: 558.7307 - val_loss: 531.7047 - val_mean_squared_error: 531.7047\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 494.6909 - mean_squared_error: 494.6909\n",
            "Epoch 1/500\n",
            "15/15 [==============================] - 1s 13ms/step - loss: 554.9515 - mean_squared_error: 554.9515 - val_loss: 531.7484 - val_mean_squared_error: 531.7484\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 551.9938 - mean_squared_error: 551.9939 - val_loss: 531.7076 - val_mean_squared_error: 531.7076\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 554.5839 - mean_squared_error: 554.5839\n",
            "Epoch 1/500\n",
            "15/15 [==============================] - 1s 14ms/step - loss: 553.4955 - mean_squared_error: 553.4955 - val_loss: 531.8401 - val_mean_squared_error: 531.8401\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 549.9149 - mean_squared_error: 549.9149 - val_loss: 531.7253 - val_mean_squared_error: 531.7253\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 573.9630 - mean_squared_error: 573.9630\n",
            "Epoch 1/500\n",
            "15/15 [==============================] - 1s 14ms/step - loss: 549.9529 - mean_squared_error: 549.9529 - val_loss: 531.7269 - val_mean_squared_error: 531.7269\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 548.2289 - mean_squared_error: 548.2289 - val_loss: 531.7061 - val_mean_squared_error: 531.7061\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 588.6932 - mean_squared_error: 588.6932\n",
            "Epoch 1/500\n",
            "15/15 [==============================] - 1s 13ms/step - loss: 538.4052 - mean_squared_error: 538.4052 - val_loss: 531.7137 - val_mean_squared_error: 531.7137\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 536.7098 - mean_squared_error: 536.7098 - val_loss: 531.7023 - val_mean_squared_error: 531.7023\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 693.4039 - mean_squared_error: 693.4039\n",
            "Epoch 1/500\n",
            "15/15 [==============================] - 1s 14ms/step - loss: 554.0341 - mean_squared_error: 554.0341 - val_loss: 531.7327 - val_mean_squared_error: 531.7327\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 552.3766 - mean_squared_error: 552.3766 - val_loss: 531.7067 - val_mean_squared_error: 531.7067\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 550.9591 - mean_squared_error: 550.9591\n",
            "Epoch 1/500\n",
            "15/15 [==============================] - 1s 13ms/step - loss: 557.8147 - mean_squared_error: 557.8146 - val_loss: 531.7449 - val_mean_squared_error: 531.7449\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 555.2856 - mean_squared_error: 555.2856 - val_loss: 531.7101 - val_mean_squared_error: 531.7100\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 524.5698 - mean_squared_error: 524.5698\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 18ms/step - loss: 564.8083 - mean_squared_error: 564.8083 - val_loss: 531.7258 - val_mean_squared_error: 531.7258\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 557.5615 - mean_squared_error: 557.5615 - val_loss: 531.7004 - val_mean_squared_error: 531.7004\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 504.9750 - mean_squared_error: 504.9750\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 19ms/step - loss: 569.5963 - mean_squared_error: 569.5963 - val_loss: 531.7422 - val_mean_squared_error: 531.7422\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 564.1320 - mean_squared_error: 564.1320 - val_loss: 531.7004 - val_mean_squared_error: 531.7004\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 446.8382 - mean_squared_error: 446.8382\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 18ms/step - loss: 552.6400 - mean_squared_error: 552.6400 - val_loss: 531.7484 - val_mean_squared_error: 531.7484\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 547.5392 - mean_squared_error: 547.5392 - val_loss: 531.7005 - val_mean_squared_error: 531.7005\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 593.7887 - mean_squared_error: 593.7887\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 18ms/step - loss: 563.2722 - mean_squared_error: 563.2722 - val_loss: 531.7449 - val_mean_squared_error: 531.7449\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 558.7302 - mean_squared_error: 558.7302 - val_loss: 531.7012 - val_mean_squared_error: 531.7012\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 494.6873 - mean_squared_error: 494.6873\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 17ms/step - loss: 558.0636 - mean_squared_error: 558.0636 - val_loss: 531.7237 - val_mean_squared_error: 531.7237\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 551.9644 - mean_squared_error: 551.9644 - val_loss: 531.7004 - val_mean_squared_error: 531.7004\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 554.5746 - mean_squared_error: 554.5746\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 16ms/step - loss: 556.8551 - mean_squared_error: 556.8551 - val_loss: 531.7477 - val_mean_squared_error: 531.7477\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 549.8443 - mean_squared_error: 549.8443 - val_loss: 531.7005 - val_mean_squared_error: 531.7005\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 573.9318 - mean_squared_error: 573.9318\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 19ms/step - loss: 555.9043 - mean_squared_error: 555.9043 - val_loss: 531.7997 - val_mean_squared_error: 531.7997\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 548.2380 - mean_squared_error: 548.2380 - val_loss: 531.7014 - val_mean_squared_error: 531.7014\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 588.6855 - mean_squared_error: 588.6855\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 18ms/step - loss: 542.0038 - mean_squared_error: 542.0038 - val_loss: 531.7736 - val_mean_squared_error: 531.7736\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 536.7252 - mean_squared_error: 536.7252 - val_loss: 531.7010 - val_mean_squared_error: 531.7010\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 693.4022 - mean_squared_error: 693.4022\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 18ms/step - loss: 556.0001 - mean_squared_error: 556.0001 - val_loss: 531.7266 - val_mean_squared_error: 531.7266\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 552.3665 - mean_squared_error: 552.3665 - val_loss: 531.7007 - val_mean_squared_error: 531.7007\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 550.9533 - mean_squared_error: 550.9533\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 17ms/step - loss: 558.3322 - mean_squared_error: 558.3322 - val_loss: 531.7156 - val_mean_squared_error: 531.7156\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 555.2624 - mean_squared_error: 555.2624 - val_loss: 531.7004 - val_mean_squared_error: 531.7004\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 524.5569 - mean_squared_error: 524.5569\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 18ms/step - loss: 558.7891 - mean_squared_error: 558.7891 - val_loss: 531.7224 - val_mean_squared_error: 531.7224\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 557.5654 - mean_squared_error: 557.5654 - val_loss: 531.7056 - val_mean_squared_error: 531.7056\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 504.9789 - mean_squared_error: 504.9789\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 17ms/step - loss: 567.7034 - mean_squared_error: 567.7034 - val_loss: 531.7902 - val_mean_squared_error: 531.7902\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 564.1778 - mean_squared_error: 564.1778 - val_loss: 531.7224 - val_mean_squared_error: 531.7224\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 446.8595 - mean_squared_error: 446.8595\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 550.9010 - mean_squared_error: 550.9010 - val_loss: 531.7388 - val_mean_squared_error: 531.7388\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 547.5519 - mean_squared_error: 547.5519 - val_loss: 531.7075 - val_mean_squared_error: 531.7075\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 593.8016 - mean_squared_error: 593.8016\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 17ms/step - loss: 565.6685 - mean_squared_error: 565.6685 - val_loss: 531.8869 - val_mean_squared_error: 531.8869\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 558.8172 - mean_squared_error: 558.8172 - val_loss: 531.7206 - val_mean_squared_error: 531.7206\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 494.7101 - mean_squared_error: 494.7101\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 19ms/step - loss: 554.1531 - mean_squared_error: 554.1531 - val_loss: 531.7982 - val_mean_squared_error: 531.7982\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 552.0127 - mean_squared_error: 552.0127 - val_loss: 531.7255 - val_mean_squared_error: 531.7255\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 554.6000 - mean_squared_error: 554.6000\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 17ms/step - loss: 553.4565 - mean_squared_error: 553.4565 - val_loss: 531.7540 - val_mean_squared_error: 531.7540\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 549.8702 - mean_squared_error: 549.8702 - val_loss: 531.7093 - val_mean_squared_error: 531.7093\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 573.9474 - mean_squared_error: 573.9474\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 17ms/step - loss: 551.4602 - mean_squared_error: 551.4602 - val_loss: 531.7604 - val_mean_squared_error: 531.7604\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 548.2505 - mean_squared_error: 548.2505 - val_loss: 531.7131 - val_mean_squared_error: 531.7131\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 588.7025 - mean_squared_error: 588.7025\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 17ms/step - loss: 539.7050 - mean_squared_error: 539.7050 - val_loss: 531.7810 - val_mean_squared_error: 531.7810\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 536.7463 - mean_squared_error: 536.7463 - val_loss: 531.7153 - val_mean_squared_error: 531.7153\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 693.4192 - mean_squared_error: 693.4192\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 17ms/step - loss: 555.4750 - mean_squared_error: 555.4750 - val_loss: 531.7427 - val_mean_squared_error: 531.7427\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 552.3887 - mean_squared_error: 552.3887 - val_loss: 531.7087 - val_mean_squared_error: 531.7087\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 550.9633 - mean_squared_error: 550.9633\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 19ms/step - loss: 558.3207 - mean_squared_error: 558.3207 - val_loss: 531.7680 - val_mean_squared_error: 531.7680\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 555.3052 - mean_squared_error: 555.3052 - val_loss: 531.7172 - val_mean_squared_error: 531.7172\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 524.5800 - mean_squared_error: 524.5800\n",
            "Epoch 1/500\n",
            "12/12 [==============================] - 1s 16ms/step - loss: 563.0308 - mean_squared_error: 563.0308 - val_loss: 531.7320 - val_mean_squared_error: 531.7320\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 557.5615 - mean_squared_error: 557.5615 - val_loss: 531.7004 - val_mean_squared_error: 531.7004\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 504.9749 - mean_squared_error: 504.9749\n",
            "Epoch 1/500\n",
            "12/12 [==============================] - 1s 17ms/step - loss: 570.6741 - mean_squared_error: 570.6741 - val_loss: 531.9254 - val_mean_squared_error: 531.9254\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 564.1912 - mean_squared_error: 564.1912 - val_loss: 531.7034 - val_mean_squared_error: 531.7034\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 446.8420 - mean_squared_error: 446.8420\n",
            "Epoch 1/500\n",
            "12/12 [==============================] - 1s 18ms/step - loss: 553.8616 - mean_squared_error: 553.8616 - val_loss: 531.7627 - val_mean_squared_error: 531.7627\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 547.5379 - mean_squared_error: 547.5379 - val_loss: 531.7009 - val_mean_squared_error: 531.7009\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 593.7892 - mean_squared_error: 593.7892\n",
            "Epoch 1/500\n",
            "12/12 [==============================] - 1s 19ms/step - loss: 563.4071 - mean_squared_error: 563.4071 - val_loss: 531.7227 - val_mean_squared_error: 531.7227\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 558.7198 - mean_squared_error: 558.7198 - val_loss: 531.7005 - val_mean_squared_error: 531.7005\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 494.6863 - mean_squared_error: 494.6863\n",
            "Epoch 1/500\n",
            "12/12 [==============================] - 1s 17ms/step - loss: 557.7578 - mean_squared_error: 557.7578 - val_loss: 531.7771 - val_mean_squared_error: 531.7771\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 551.9840 - mean_squared_error: 551.9840 - val_loss: 531.7017 - val_mean_squared_error: 531.7017\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 554.5760 - mean_squared_error: 554.5760\n",
            "Epoch 1/500\n",
            "12/12 [==============================] - 1s 17ms/step - loss: 558.9182 - mean_squared_error: 558.9182 - val_loss: 531.8583 - val_mean_squared_error: 531.8583\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 549.8815 - mean_squared_error: 549.8815 - val_loss: 531.7025 - val_mean_squared_error: 531.7025\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 573.9342 - mean_squared_error: 573.9342\n",
            "Epoch 1/500\n",
            "12/12 [==============================] - 1s 18ms/step - loss: 552.4828 - mean_squared_error: 552.4828 - val_loss: 531.7114 - val_mean_squared_error: 531.7114\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 548.2133 - mean_squared_error: 548.2133 - val_loss: 531.7003 - val_mean_squared_error: 531.7003\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 588.6839 - mean_squared_error: 588.6839\n",
            "Epoch 1/500\n",
            "12/12 [==============================] - 1s 17ms/step - loss: 543.3913 - mean_squared_error: 543.3913 - val_loss: 531.8756 - val_mean_squared_error: 531.8756\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 536.7527 - mean_squared_error: 536.7527 - val_loss: 531.7023 - val_mean_squared_error: 531.7023\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 693.4037 - mean_squared_error: 693.4037\n",
            "Epoch 1/500\n",
            "12/12 [==============================] - 1s 18ms/step - loss: 558.6297 - mean_squared_error: 558.6297 - val_loss: 531.7590 - val_mean_squared_error: 531.7590\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 552.3800 - mean_squared_error: 552.3800 - val_loss: 531.7015 - val_mean_squared_error: 531.7015\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 550.9542 - mean_squared_error: 550.9542\n",
            "Epoch 1/500\n",
            "12/12 [==============================] - 1s 17ms/step - loss: 561.8263 - mean_squared_error: 561.8263 - val_loss: 531.7476 - val_mean_squared_error: 531.7476\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 555.2700 - mean_squared_error: 555.2700 - val_loss: 531.7005 - val_mean_squared_error: 531.7005\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 524.5569 - mean_squared_error: 524.5569\n",
            "Epoch 1/500\n",
            "12/12 [==============================] - 1s 18ms/step - loss: 560.2271 - mean_squared_error: 560.2271 - val_loss: 531.7360 - val_mean_squared_error: 531.7360\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 557.5746 - mean_squared_error: 557.5746 - val_loss: 531.7050 - val_mean_squared_error: 531.7050\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 504.9801 - mean_squared_error: 504.9801\n",
            "Epoch 1/500\n",
            "12/12 [==============================] - 1s 17ms/step - loss: 566.8371 - mean_squared_error: 566.8371 - val_loss: 531.7350 - val_mean_squared_error: 531.7350\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 564.1387 - mean_squared_error: 564.1387 - val_loss: 531.7087 - val_mean_squared_error: 531.7087\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 446.8443 - mean_squared_error: 446.8443\n",
            "Epoch 1/500\n",
            "12/12 [==============================] - 1s 17ms/step - loss: 550.0269 - mean_squared_error: 550.0269 - val_loss: 531.7394 - val_mean_squared_error: 531.7394\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 547.5480 - mean_squared_error: 547.5480 - val_loss: 531.7076 - val_mean_squared_error: 531.7076\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 593.8001 - mean_squared_error: 593.8001\n",
            "Epoch 1/500\n",
            "12/12 [==============================] - 1s 16ms/step - loss: 561.4045 - mean_squared_error: 561.4045 - val_loss: 531.7283 - val_mean_squared_error: 531.7283\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 558.7369 - mean_squared_error: 558.7369 - val_loss: 531.7041 - val_mean_squared_error: 531.7041\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 494.6917 - mean_squared_error: 494.6917\n",
            "Epoch 1/500\n",
            "12/12 [==============================] - 1s 18ms/step - loss: 555.1343 - mean_squared_error: 555.1343 - val_loss: 531.7737 - val_mean_squared_error: 531.7737\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 551.9962 - mean_squared_error: 551.9962 - val_loss: 531.7090 - val_mean_squared_error: 531.7090\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 554.5836 - mean_squared_error: 554.5836\n",
            "Epoch 1/500\n",
            "12/12 [==============================] - 1s 18ms/step - loss: 553.6733 - mean_squared_error: 553.6733 - val_loss: 531.7391 - val_mean_squared_error: 531.7391\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 549.8564 - mean_squared_error: 549.8564 - val_loss: 531.7056 - val_mean_squared_error: 531.7056\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 573.9393 - mean_squared_error: 573.9393\n",
            "Epoch 1/500\n",
            "12/12 [==============================] - 1s 16ms/step - loss: 550.5021 - mean_squared_error: 550.5021 - val_loss: 531.7495 - val_mean_squared_error: 531.7495\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 548.2390 - mean_squared_error: 548.2390 - val_loss: 531.7121 - val_mean_squared_error: 531.7121\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 588.6965 - mean_squared_error: 588.6965\n",
            "Epoch 1/500\n",
            "12/12 [==============================] - 1s 18ms/step - loss: 539.2726 - mean_squared_error: 539.2726 - val_loss: 531.7421 - val_mean_squared_error: 531.7421\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 536.7289 - mean_squared_error: 536.7289 - val_loss: 531.7070 - val_mean_squared_error: 531.7070\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 693.4123 - mean_squared_error: 693.4123\n",
            "Epoch 1/500\n",
            "12/12 [==============================] - 1s 20ms/step - loss: 555.5422 - mean_squared_error: 555.5422 - val_loss: 531.7597 - val_mean_squared_error: 531.7597\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 552.3879 - mean_squared_error: 552.3879 - val_loss: 531.7108 - val_mean_squared_error: 531.7108\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 550.9622 - mean_squared_error: 550.9622\n",
            "Epoch 1/500\n",
            "12/12 [==============================] - 1s 16ms/step - loss: 557.2247 - mean_squared_error: 557.2247 - val_loss: 531.7344 - val_mean_squared_error: 531.7344\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 555.2794 - mean_squared_error: 555.2794 - val_loss: 531.7083 - val_mean_squared_error: 531.7083\n",
            "Epoch 00002: early stopping\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 524.5668 - mean_squared_error: 524.5668\n",
            "Epoch 1/100\n",
            "17/17 [==============================] - 1s 13ms/step - loss: 559.7407 - mean_squared_error: 559.7407 - val_loss: 531.8004 - val_mean_squared_error: 531.8004\n",
            "Epoch 2/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 552.2450 - mean_squared_error: 552.2450 - val_loss: 531.7014 - val_mean_squared_error: 531.7015\n",
            "Epoch 00002: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_parameters = grid_search.best_params_\n",
        "print(\"best_parameters: \",best_parameters)\n",
        "best_accuracy = grid_search.best_score_\n",
        "print(\"best_accuracy: \",best_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUMrsXgcTRsE",
        "outputId": "85318c00-25f7-48f8-86c0-f5d1e00aadad"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_parameters:  {'batch_size': 25, 'epochs': 100, 'optimizer': 'adam'}\n",
            "best_accuracy:  -552.6388275146485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loss Functions"
      ],
      "metadata": {
        "id": "y6L1_kEYU6AO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dflist = []\n",
        "\n",
        "loss_functions = ['mean_squared_error','mean_absolute_error']\n",
        "\n",
        "for ls in loss_functions:\n",
        "  # Initialising the ANN\n",
        "  Regressor = Sequential()\n",
        "\n",
        "  # Adding the input layer and the first hidden layer\n",
        "  Regressor.add(Dense(units = 100, kernel_initializer = 'uniform', activation = 'relu', input_dim = 13))\n",
        "\n",
        "  # Adding the second hidden layer\n",
        "  Regressor.add(Dense(units = 50, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "\n",
        "  # Adding the output layer\n",
        "  Regressor.add(Dense(units = 1))\n",
        "\n",
        "  # Compiling the ANN\n",
        "  Regressor.compile(optimizer = 'adam', loss = ls, metrics=['mse'])\n",
        "\n",
        "  h = Regressor.fit(X_train,y_train,epochs=25,batch_size=16,verbose=1)\n",
        "    \n",
        "  dflist.append(pd.DataFrame(h.history,index=h.epoch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VeVtxcTU66i",
        "outputId": "23cf6e79-72de-476a-f1b0-eb1cbcb184c5"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 104.0171 - mse: 104.0171\n",
            "Epoch 2/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 62.0579 - mse: 62.0579\n",
            "Epoch 3/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 54.5847 - mse: 54.5847\n",
            "Epoch 4/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 52.6241 - mse: 52.6241\n",
            "Epoch 5/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 54.7090 - mse: 54.7090\n",
            "Epoch 6/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 48.1296 - mse: 48.1296\n",
            "Epoch 7/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 46.6892 - mse: 46.6892\n",
            "Epoch 8/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 44.8613 - mse: 44.8613\n",
            "Epoch 9/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 44.0189 - mse: 44.0189\n",
            "Epoch 10/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 38.4960 - mse: 38.4960\n",
            "Epoch 11/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 41.8963 - mse: 41.8963\n",
            "Epoch 12/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 36.1443 - mse: 36.1443\n",
            "Epoch 13/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 33.8784 - mse: 33.8784\n",
            "Epoch 14/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 34.0573 - mse: 34.0573\n",
            "Epoch 15/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 32.4641 - mse: 32.4641\n",
            "Epoch 16/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 28.6940 - mse: 28.6940\n",
            "Epoch 17/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 29.0924 - mse: 29.0924\n",
            "Epoch 18/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 27.9150 - mse: 27.9150\n",
            "Epoch 19/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 27.6976 - mse: 27.6976\n",
            "Epoch 20/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 25.0714 - mse: 25.0714\n",
            "Epoch 21/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 25.9704 - mse: 25.9704\n",
            "Epoch 22/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 25.4305 - mse: 25.4305\n",
            "Epoch 23/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 23.2200 - mse: 23.2200\n",
            "Epoch 24/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 23.0256 - mse: 23.0256\n",
            "Epoch 25/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 21.4658 - mse: 21.4658\n",
            "Epoch 1/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 10.1181 - mse: 181.0355\n",
            "Epoch 2/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.6108 - mse: 65.5357\n",
            "Epoch 3/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.2628 - mse: 60.7506\n",
            "Epoch 4/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.1051 - mse: 57.3406\n",
            "Epoch 5/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.0598 - mse: 58.1060\n",
            "Epoch 6/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.1299 - mse: 55.7583\n",
            "Epoch 7/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.8266 - mse: 52.2453\n",
            "Epoch 8/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.6447 - mse: 49.7093\n",
            "Epoch 9/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.7844 - mse: 49.8090\n",
            "Epoch 10/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.5969 - mse: 49.7968\n",
            "Epoch 11/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.5189 - mse: 48.3373\n",
            "Epoch 12/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.4692 - mse: 44.5168\n",
            "Epoch 13/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.4070 - mse: 44.9627\n",
            "Epoch 14/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.3153 - mse: 40.4845\n",
            "Epoch 15/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.2822 - mse: 39.3650\n",
            "Epoch 16/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.1694 - mse: 39.1906\n",
            "Epoch 17/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.4493 - mse: 39.6346\n",
            "Epoch 18/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.1017 - mse: 37.3740\n",
            "Epoch 19/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.0961 - mse: 36.4430\n",
            "Epoch 20/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.0643 - mse: 35.4388\n",
            "Epoch 21/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.0897 - mse: 35.3647\n",
            "Epoch 22/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 3.8974 - mse: 32.3972\n",
            "Epoch 23/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 3.8458 - mse: 31.4112\n",
            "Epoch 24/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 3.8091 - mse: 31.2869\n",
            "Epoch 25/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 3.7501 - mse: 29.9165\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "historydf = pd.concat(dflist,axis=1)\n",
        "metrics_reported = dflist[0].columns\n",
        "idx = pd.MultiIndex.from_product([loss_functions,metrics_reported],names=['loss_functions','metric'])\n",
        "\n",
        "print(historydf.shape)\n",
        "#idx.shape\n",
        "historydf.columns = idx\n",
        "\n",
        "\n",
        "print(historydf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBcmtR0IWjXt",
        "outputId": "451a88f4-b2c8-4299-f752-b419d5fdf90a"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25, 4)\n",
            "loss_functions mean_squared_error             mean_absolute_error            \n",
            "metric                       loss         mse                loss         mse\n",
            "0                      104.017105  104.017105           10.118140  181.035492\n",
            "1                       62.057873   62.057873            5.610798   65.535667\n",
            "2                       54.584671   54.584671            5.262835   60.750595\n",
            "3                       52.624146   52.624146            5.105100   57.340588\n",
            "4                       54.708984   54.708984            5.059758   58.105980\n",
            "5                       48.129635   48.129635            5.129890   55.758286\n",
            "6                       46.689159   46.689159            4.826567   52.245277\n",
            "7                       44.861347   44.861347            4.644700   49.709339\n",
            "8                       44.018860   44.018860            4.784441   49.809032\n",
            "9                       38.495972   38.495972            4.596862   49.796761\n",
            "10                      41.896263   41.896263            4.518920   48.337334\n",
            "11                      36.144337   36.144337            4.469172   44.516750\n",
            "12                      33.878429   33.878429            4.406966   44.962749\n",
            "13                      34.057251   34.057251            4.315339   40.484528\n",
            "14                      32.464050   32.464050            4.282226   39.365017\n",
            "15                      28.693972   28.693972            4.169407   39.190632\n",
            "16                      29.092394   29.092394            4.449297   39.634563\n",
            "17                      27.914995   27.914995            4.101720   37.374043\n",
            "18                      27.697577   27.697577            4.096072   36.443005\n",
            "19                      25.071436   25.071436            4.064339   35.438770\n",
            "20                      25.970358   25.970358            4.089715   35.364735\n",
            "21                      25.430502   25.430502            3.897358   32.397213\n",
            "22                      23.219980   23.219980            3.845766   31.411249\n",
            "23                      23.025600   23.025600            3.809099   31.286943\n",
            "24                      21.465836   21.465836            3.750100   29.916452\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Learning Rates"
      ],
      "metadata": {
        "id": "B3urxh9MYZLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dflist = []\n",
        "\n",
        "learning_rates = [0.01,0.05,0.10,0.5]\n",
        "\n",
        "for lr in learning_rates:\n",
        "  # Initialising the ANN\n",
        "  Regressor = Sequential()\n",
        "\n",
        "  # Adding the input layer and the first hidden layer\n",
        "  Regressor.add(Dense(units = 100, kernel_initializer = 'uniform', activation = 'relu', input_dim = 13))\n",
        "\n",
        "  # Adding the second hidden layer\n",
        "  Regressor.add(Dense(units = 50, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "\n",
        "  # Adding the output layer\n",
        "  Regressor.add(Dense(units = 1))\n",
        "\n",
        "  # Compiling the ANN\n",
        "  Regressor.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics=['mse'])\n",
        "\n",
        "  h = Regressor.fit(X_train,y_train,epochs=25,batch_size=16,verbose=1)\n",
        "    \n",
        "  dflist.append(pd.DataFrame(h.history,index=h.epoch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Z6XyJiGYaJy",
        "outputId": "c635e5f9-0a51-4334-95cc-76e6dde55022"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 233.6411 - mse: 233.6411\n",
            "Epoch 2/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 65.9747 - mse: 65.9747\n",
            "Epoch 3/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 57.9789 - mse: 57.9789\n",
            "Epoch 4/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 54.6987 - mse: 54.6987\n",
            "Epoch 5/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 51.9445 - mse: 51.9445\n",
            "Epoch 6/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 50.4768 - mse: 50.4768\n",
            "Epoch 7/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 48.9494 - mse: 48.9494\n",
            "Epoch 8/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 52.7992 - mse: 52.7992\n",
            "Epoch 9/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 45.0391 - mse: 45.0391\n",
            "Epoch 10/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 45.4792 - mse: 45.4792\n",
            "Epoch 11/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 45.8215 - mse: 45.8215\n",
            "Epoch 12/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 44.3511 - mse: 44.3511\n",
            "Epoch 13/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 39.9207 - mse: 39.9207\n",
            "Epoch 14/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 45.6780 - mse: 45.6780\n",
            "Epoch 15/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 42.6194 - mse: 42.6194\n",
            "Epoch 16/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 37.7104 - mse: 37.7104\n",
            "Epoch 17/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 34.3838 - mse: 34.3838\n",
            "Epoch 18/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 33.8664 - mse: 33.8664\n",
            "Epoch 19/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 32.1640 - mse: 32.1640\n",
            "Epoch 20/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 32.7684 - mse: 32.7684\n",
            "Epoch 21/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 30.2929 - mse: 30.2929\n",
            "Epoch 22/25\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 30.2242 - mse: 30.2242\n",
            "Epoch 23/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 30.0537 - mse: 30.0537\n",
            "Epoch 24/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 31.9059 - mse: 31.9059\n",
            "Epoch 25/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 28.3544 - mse: 28.3544\n",
            "Epoch 1/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 242.5977 - mse: 242.5977\n",
            "Epoch 2/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 72.5071 - mse: 72.5071\n",
            "Epoch 3/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 58.1330 - mse: 58.1330\n",
            "Epoch 4/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 56.3659 - mse: 56.3659\n",
            "Epoch 5/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 53.9178 - mse: 53.9178\n",
            "Epoch 6/25\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 51.5869 - mse: 51.5869\n",
            "Epoch 7/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 51.9501 - mse: 51.9501\n",
            "Epoch 8/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 50.0603 - mse: 50.0603\n",
            "Epoch 9/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 46.9756 - mse: 46.9756\n",
            "Epoch 10/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 44.6274 - mse: 44.6274\n",
            "Epoch 11/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 41.9236 - mse: 41.9236\n",
            "Epoch 12/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 39.9497 - mse: 39.9497\n",
            "Epoch 13/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 39.0187 - mse: 39.0187\n",
            "Epoch 14/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 39.4312 - mse: 39.4312\n",
            "Epoch 15/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 35.5887 - mse: 35.5887\n",
            "Epoch 16/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 34.3051 - mse: 34.3051\n",
            "Epoch 17/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 33.6446 - mse: 33.6446\n",
            "Epoch 18/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 31.7112 - mse: 31.7112\n",
            "Epoch 19/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 29.9409 - mse: 29.9409\n",
            "Epoch 20/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 28.1100 - mse: 28.1100\n",
            "Epoch 21/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 28.6656 - mse: 28.6656\n",
            "Epoch 22/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 27.5791 - mse: 27.5791\n",
            "Epoch 23/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 27.8688 - mse: 27.8688\n",
            "Epoch 24/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 26.3440 - mse: 26.3440\n",
            "Epoch 25/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 26.5599 - mse: 26.5599\n",
            "Epoch 1/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 149.3223 - mse: 149.3223\n",
            "Epoch 2/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 61.0160 - mse: 61.0160\n",
            "Epoch 3/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 55.6269 - mse: 55.6269\n",
            "Epoch 4/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 54.2766 - mse: 54.2766\n",
            "Epoch 5/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 53.1328 - mse: 53.1328\n",
            "Epoch 6/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 50.7013 - mse: 50.7013\n",
            "Epoch 7/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 48.5183 - mse: 48.5183\n",
            "Epoch 8/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 47.0924 - mse: 47.0924\n",
            "Epoch 9/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 43.9258 - mse: 43.9258\n",
            "Epoch 10/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 41.4377 - mse: 41.4377\n",
            "Epoch 11/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 39.5038 - mse: 39.5038\n",
            "Epoch 12/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 40.1138 - mse: 40.1138\n",
            "Epoch 13/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 34.8193 - mse: 34.8193\n",
            "Epoch 14/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 35.1762 - mse: 35.1762\n",
            "Epoch 15/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 36.0114 - mse: 36.0114\n",
            "Epoch 16/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 34.8432 - mse: 34.8432\n",
            "Epoch 17/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 33.3531 - mse: 33.3531\n",
            "Epoch 18/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 30.5800 - mse: 30.5800\n",
            "Epoch 19/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 33.5034 - mse: 33.5034\n",
            "Epoch 20/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 31.6129 - mse: 31.6129\n",
            "Epoch 21/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 35.3239 - mse: 35.3239\n",
            "Epoch 22/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 28.0840 - mse: 28.0840\n",
            "Epoch 23/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 27.5936 - mse: 27.5936\n",
            "Epoch 24/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 32.4343 - mse: 32.4343\n",
            "Epoch 25/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 25.2483 - mse: 25.2483\n",
            "Epoch 1/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 167.0673 - mse: 167.0673\n",
            "Epoch 2/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 61.8926 - mse: 61.8926\n",
            "Epoch 3/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 56.6920 - mse: 56.6920\n",
            "Epoch 4/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 57.4510 - mse: 57.4510\n",
            "Epoch 5/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 52.6636 - mse: 52.6636\n",
            "Epoch 6/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 53.6297 - mse: 53.6297\n",
            "Epoch 7/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 50.0743 - mse: 50.0743\n",
            "Epoch 8/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 49.2358 - mse: 49.2358\n",
            "Epoch 9/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 45.6979 - mse: 45.6979\n",
            "Epoch 10/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 48.5203 - mse: 48.5203\n",
            "Epoch 11/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 44.1822 - mse: 44.1822\n",
            "Epoch 12/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 41.4755 - mse: 41.4755\n",
            "Epoch 13/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 41.7227 - mse: 41.7227\n",
            "Epoch 14/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 40.3471 - mse: 40.3471\n",
            "Epoch 15/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 35.3472 - mse: 35.3472\n",
            "Epoch 16/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 33.9090 - mse: 33.9090\n",
            "Epoch 17/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 33.0000 - mse: 33.0000\n",
            "Epoch 18/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 35.6124 - mse: 35.6124\n",
            "Epoch 19/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 31.1089 - mse: 31.1089\n",
            "Epoch 20/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 29.2775 - mse: 29.2775\n",
            "Epoch 21/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 27.2917 - mse: 27.2917\n",
            "Epoch 22/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 28.3051 - mse: 28.3051\n",
            "Epoch 23/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 27.3191 - mse: 27.3191\n",
            "Epoch 24/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 27.3288 - mse: 27.3288\n",
            "Epoch 25/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 25.3268 - mse: 25.3268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "historydf = pd.concat(dflist,axis=1)\n",
        "metrics_reported = dflist[0].columns\n",
        "idx = pd.MultiIndex.from_product([learning_rates,metrics_reported],names=['learning_rates','metric'])\n",
        "\n",
        "idx.shape\n",
        "historydf.columns = idx\n",
        "\n",
        "print(historydf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzXoe3TDZSYD",
        "outputId": "a5998a5c-2aea-4630-9269-267430cef33e"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learning_rates        0.01              ...        0.50            \n",
            "metric                loss         mse  ...        loss         mse\n",
            "0               233.641113  233.641113  ...  167.067261  167.067261\n",
            "1                65.974709   65.974709  ...   61.892639   61.892639\n",
            "2                57.978920   57.978920  ...   56.691978   56.691978\n",
            "3                54.698658   54.698658  ...   57.450977   57.450977\n",
            "4                51.944519   51.944519  ...   52.663578   52.663578\n",
            "5                50.476803   50.476803  ...   53.629700   53.629700\n",
            "6                48.949364   48.949364  ...   50.074329   50.074329\n",
            "7                52.799213   52.799213  ...   49.235756   49.235756\n",
            "8                45.039097   45.039097  ...   45.697868   45.697868\n",
            "9                45.479210   45.479210  ...   48.520344   48.520344\n",
            "10               45.821472   45.821472  ...   44.182243   44.182243\n",
            "11               44.351086   44.351086  ...   41.475544   41.475544\n",
            "12               39.920715   39.920715  ...   41.722687   41.722687\n",
            "13               45.678017   45.678017  ...   40.347145   40.347145\n",
            "14               42.619362   42.619362  ...   35.347206   35.347206\n",
            "15               37.710449   37.710449  ...   33.909004   33.909004\n",
            "16               34.383804   34.383804  ...   33.000011   33.000011\n",
            "17               33.866447   33.866447  ...   35.612431   35.612431\n",
            "18               32.164001   32.164001  ...   31.108850   31.108850\n",
            "19               32.768414   32.768414  ...   29.277485   29.277485\n",
            "20               30.292950   30.292950  ...   27.291712   27.291712\n",
            "21               30.224245   30.224245  ...   28.305149   28.305149\n",
            "22               30.053656   30.053656  ...   27.319149   27.319149\n",
            "23               31.905933   31.905933  ...   27.328756   27.328756\n",
            "24               28.354401   28.354401  ...   25.326790   25.326790\n",
            "\n",
            "[25 rows x 8 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Batch sizes"
      ],
      "metadata": {
        "id": "IGFEijJ-bPeN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dflist = []\n",
        "\n",
        "batch_sizes = [16,32,64,128]\n",
        "\n",
        "for bs in batch_sizes:\n",
        "  # Initialising the ANN\n",
        "  Regressor = Sequential()\n",
        "\n",
        "  # Adding the input layer and the first hidden layer\n",
        "  Regressor.add(Dense(units = 100, kernel_initializer = 'uniform', activation = 'relu', input_dim = 13))\n",
        "\n",
        "  # Adding the second hidden layer\n",
        "  Regressor.add(Dense(units = 50, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "\n",
        "  # Adding the output layer\n",
        "  Regressor.add(Dense(units = 1))\n",
        "\n",
        "  # Compiling the ANN\n",
        "  Regressor.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics=['mse'])\n",
        "\n",
        "  h = Regressor.fit(X_train,y_train,epochs=25,batch_size=bs,verbose=1)\n",
        "    \n",
        "  dflist.append(pd.DataFrame(h.history,index=h.epoch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lf86EOpGfTzy",
        "outputId": "f3a86efb-aab5-4593-a86a-61d49fa0729f"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 183.0020 - mse: 183.0020\n",
            "Epoch 2/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 64.1055 - mse: 64.1055\n",
            "Epoch 3/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 57.1206 - mse: 57.1206\n",
            "Epoch 4/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 54.3069 - mse: 54.3069\n",
            "Epoch 5/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 56.8042 - mse: 56.8042\n",
            "Epoch 6/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 51.1898 - mse: 51.1898\n",
            "Epoch 7/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 51.7844 - mse: 51.7844\n",
            "Epoch 8/25\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 48.2729 - mse: 48.2729\n",
            "Epoch 9/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 46.4122 - mse: 46.4122\n",
            "Epoch 10/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 43.5450 - mse: 43.5450\n",
            "Epoch 11/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 42.6823 - mse: 42.6823\n",
            "Epoch 12/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 41.1750 - mse: 41.1750\n",
            "Epoch 13/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 38.4138 - mse: 38.4138\n",
            "Epoch 14/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 36.9786 - mse: 36.9786\n",
            "Epoch 15/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 35.4924 - mse: 35.4924\n",
            "Epoch 16/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 33.4019 - mse: 33.4019\n",
            "Epoch 17/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 39.6824 - mse: 39.6824\n",
            "Epoch 18/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 31.0515 - mse: 31.0515\n",
            "Epoch 19/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 31.6522 - mse: 31.6522\n",
            "Epoch 20/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 32.8382 - mse: 32.8382\n",
            "Epoch 21/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 29.3349 - mse: 29.3349\n",
            "Epoch 22/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 28.2160 - mse: 28.2160\n",
            "Epoch 23/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 27.3184 - mse: 27.3184\n",
            "Epoch 24/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 26.3970 - mse: 26.3970\n",
            "Epoch 25/25\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 25.9892 - mse: 25.9892\n",
            "Epoch 1/25\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 176.1966 - mse: 176.1966\n",
            "Epoch 2/25\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 87.5395 - mse: 87.5395\n",
            "Epoch 3/25\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 63.7420 - mse: 63.7420\n",
            "Epoch 4/25\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 61.2409 - mse: 61.2409\n",
            "Epoch 5/25\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 59.7918 - mse: 59.7918\n",
            "Epoch 6/25\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 57.0174 - mse: 57.0174\n",
            "Epoch 7/25\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 54.7215 - mse: 54.7215\n",
            "Epoch 8/25\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 52.9795 - mse: 52.9795\n",
            "Epoch 9/25\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 55.2518 - mse: 55.2518\n",
            "Epoch 10/25\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 50.7866 - mse: 50.7866\n",
            "Epoch 11/25\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 49.9254 - mse: 49.9254\n",
            "Epoch 12/25\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 48.6601 - mse: 48.6601\n",
            "Epoch 13/25\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 47.9934 - mse: 47.9934\n",
            "Epoch 14/25\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 46.8113 - mse: 46.8113\n",
            "Epoch 15/25\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 45.8711 - mse: 45.8711\n",
            "Epoch 16/25\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 44.2850 - mse: 44.2850\n",
            "Epoch 17/25\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 42.7097 - mse: 42.7097\n",
            "Epoch 18/25\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 41.5106 - mse: 41.5106\n",
            "Epoch 19/25\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 45.4755 - mse: 45.4755\n",
            "Epoch 20/25\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 42.0064 - mse: 42.0064\n",
            "Epoch 21/25\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 42.9059 - mse: 42.9059\n",
            "Epoch 22/25\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 37.3140 - mse: 37.3140\n",
            "Epoch 23/25\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 35.7859 - mse: 35.7859\n",
            "Epoch 24/25\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 35.8165 - mse: 35.8165\n",
            "Epoch 25/25\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 38.1597 - mse: 38.1597\n",
            "Epoch 1/25\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 278.9001 - mse: 278.9001\n",
            "Epoch 2/25\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 156.8385 - mse: 156.8385\n",
            "Epoch 3/25\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 88.1950 - mse: 88.1950\n",
            "Epoch 4/25\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 71.8322 - mse: 71.8322\n",
            "Epoch 5/25\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 64.7072 - mse: 64.7072\n",
            "Epoch 6/25\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 60.7305 - mse: 60.7305\n",
            "Epoch 7/25\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 58.5750 - mse: 58.5750\n",
            "Epoch 8/25\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 57.1416 - mse: 57.1416\n",
            "Epoch 9/25\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 54.9246 - mse: 54.9246\n",
            "Epoch 10/25\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 54.8387 - mse: 54.8387\n",
            "Epoch 11/25\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 54.0568 - mse: 54.0568\n",
            "Epoch 12/25\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 53.3748 - mse: 53.3748\n",
            "Epoch 13/25\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 53.0977 - mse: 53.0977\n",
            "Epoch 14/25\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 52.1271 - mse: 52.1271\n",
            "Epoch 15/25\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 51.4509 - mse: 51.4509\n",
            "Epoch 16/25\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 51.2186 - mse: 51.2186\n",
            "Epoch 17/25\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 50.4793 - mse: 50.4793\n",
            "Epoch 18/25\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 49.5749 - mse: 49.5749\n",
            "Epoch 19/25\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 49.8868 - mse: 49.8868\n",
            "Epoch 20/25\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 49.0394 - mse: 49.0394\n",
            "Epoch 21/25\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 48.6153 - mse: 48.6153\n",
            "Epoch 22/25\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 47.4691 - mse: 47.4691\n",
            "Epoch 23/25\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 46.3782 - mse: 46.3782\n",
            "Epoch 24/25\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 46.0175 - mse: 46.0175\n",
            "Epoch 25/25\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 46.4748 - mse: 46.4748\n",
            "Epoch 1/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 660.3955 - mse: 660.3955\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 221.5645 - mse: 221.5645\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 178.3287 - mse: 178.3287\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 167.3305 - mse: 167.3305\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 111.2137 - mse: 111.2137\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 88.8717 - mse: 88.8717\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 76.0157 - mse: 76.0157\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 62.9293 - mse: 62.9293\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 62.5740 - mse: 62.5740\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 58.7655 - mse: 58.7655\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 56.6328 - mse: 56.6328\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 56.6283 - mse: 56.6283\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 55.1915 - mse: 55.1915\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 54.7105 - mse: 54.7105\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 53.7888 - mse: 53.7888\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 53.0915 - mse: 53.0915\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 52.7961 - mse: 52.7961\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 52.0974 - mse: 52.0974\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 52.3549 - mse: 52.3549\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 52.6961 - mse: 52.6961\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 51.2654 - mse: 51.2654\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 51.8081 - mse: 51.8081\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 51.9181 - mse: 51.9181\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 50.8002 - mse: 50.8002\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 49.2587 - mse: 49.2587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "historydf = pd.concat(dflist,axis=1)\n",
        "metrics_reported = dflist[0].columns\n",
        "idx = pd.MultiIndex.from_product([batch_sizes,metrics_reported],names=['batch_sizes','metric'])\n",
        "\n",
        "idx.shape\n",
        "historydf.columns = idx\n",
        "\n",
        "print(historydf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbigtaSofndb",
        "outputId": "58f9f820-cd06-42a0-e5dd-02a00149efee"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_sizes         16               ...         128            \n",
            "metric             loss         mse  ...        loss         mse\n",
            "0            183.001968  183.001968  ...  660.395508  660.395508\n",
            "1             64.105515   64.105515  ...  221.564514  221.564514\n",
            "2             57.120640   57.120640  ...  178.328690  178.328690\n",
            "3             54.306934   54.306934  ...  167.330490  167.330490\n",
            "4             56.804161   56.804161  ...  111.213699  111.213699\n",
            "5             51.189846   51.189846  ...   88.871712   88.871712\n",
            "6             51.784382   51.784382  ...   76.015701   76.015701\n",
            "7             48.272938   48.272938  ...   62.929340   62.929340\n",
            "8             46.412178   46.412178  ...   62.573952   62.573952\n",
            "9             43.545048   43.545048  ...   58.765549   58.765549\n",
            "10            42.682262   42.682262  ...   56.632782   56.632782\n",
            "11            41.175037   41.175037  ...   56.628262   56.628262\n",
            "12            38.413822   38.413822  ...   55.191528   55.191528\n",
            "13            36.978592   36.978592  ...   54.710468   54.710468\n",
            "14            35.492382   35.492382  ...   53.788780   53.788780\n",
            "15            33.401871   33.401871  ...   53.091473   53.091473\n",
            "16            39.682407   39.682407  ...   52.796062   52.796062\n",
            "17            31.051519   31.051519  ...   52.097424   52.097424\n",
            "18            31.652218   31.652218  ...   52.354877   52.354877\n",
            "19            32.838165   32.838165  ...   52.696144   52.696144\n",
            "20            29.334940   29.334940  ...   51.265442   51.265446\n",
            "21            28.216019   28.216019  ...   51.808121   51.808121\n",
            "22            27.318434   27.318434  ...   51.918148   51.918148\n",
            "23            26.396961   26.396961  ...   50.800201   50.800201\n",
            "24            25.989193   25.989193  ...   49.258720   49.258720\n",
            "\n",
            "[25 rows x 8 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Optimizers"
      ],
      "metadata": {
        "id": "bQuivlm3f6Pu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "dflist = []\n",
        "\n",
        "\n",
        "\n",
        "optimizers = ['keras.optimizers.Adam()','keras.optimizers.Adagrad()', 'keras.optimizers.RMSprop()']\n",
        "\n",
        "\n",
        "\n",
        "for opt_name in optimizers:\n",
        "  # Initialising the ANN\n",
        "  Regressor = Sequential()\n",
        "\n",
        "  # Adding the input layer and the first hidden layer\n",
        "  Regressor.add(Dense(units = 100, kernel_initializer = 'uniform', activation = 'relu', input_dim = 13))\n",
        "\n",
        "  # Adding the second hidden layer\n",
        "  Regressor.add(Dense(units = 50, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "\n",
        "  # Adding the output layer\n",
        "  Regressor.add(Dense(units = 1))\n",
        "\n",
        "  # Compiling the ANN\n",
        "  Regressor.compile(optimizer = eval(opt_name), loss = 'mean_squared_error', metrics=['mse'])\n",
        "\n",
        "  h = Regressor.fit(X_train,y_train,epochs=25,batch_size=bs,verbose=1)\n",
        "    \n",
        "  dflist.append(pd.DataFrame(h.history,index=h.epoch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJlKlFzSf7Ls",
        "outputId": "ccefa8ca-dc76-4306-82cf-63055707605b"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 517.1107 - mse: 517.1107\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 265.0422 - mse: 265.0422\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 161.3193 - mse: 161.3193\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 157.1566 - mse: 157.1566\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 135.3710 - mse: 135.3710\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 101.6861 - mse: 101.6861\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 86.6147 - mse: 86.6147\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 75.8789 - mse: 75.8789\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 66.7628 - mse: 66.7628\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 65.2161 - mse: 65.2161\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 63.7249 - mse: 63.7249\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 61.8076 - mse: 61.8076\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 62.0742 - mse: 62.0742\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 60.9253 - mse: 60.9253\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 58.7691 - mse: 58.7691\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 59.5077 - mse: 59.5077\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 57.2917 - mse: 57.2917\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 57.7207 - mse: 57.7207\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 56.4507 - mse: 56.4507\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 55.3637 - mse: 55.3637\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 55.4206 - mse: 55.4206\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 54.5506 - mse: 54.5506\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 53.8383 - mse: 53.8383\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 53.4781 - mse: 53.4781\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 53.1564 - mse: 53.1564\n",
            "Epoch 1/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 509.3267 - mse: 509.3267\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 343.9459 - mse: 343.9459\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 257.8726 - mse: 257.8726\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 203.6270 - mse: 203.6270\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 172.4440 - mse: 172.4440\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 150.8441 - mse: 150.8441\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 133.8813 - mse: 133.8813\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 122.3325 - mse: 122.3325\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 112.7050 - mse: 112.7050\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 105.9809 - mse: 105.9809\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 100.2841 - mse: 100.2841\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 95.9749 - mse: 95.9749\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 91.3031 - mse: 91.3031\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 87.4491 - mse: 87.4491\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 84.6199 - mse: 84.6199\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 81.6916 - mse: 81.6916\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 79.0947 - mse: 79.0947\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 77.0842 - mse: 77.0842\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 74.5750 - mse: 74.5750\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 73.1545 - mse: 73.1545\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 72.0465 - mse: 72.0465\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 70.7270 - mse: 70.7270\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 69.7818 - mse: 69.7818\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 68.9422 - mse: 68.9422\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 68.0188 - mse: 68.0188\n",
            "Epoch 1/25\n",
            "4/4 [==============================] - 1s 3ms/step - loss: 339.6399 - mse: 339.6399\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 97.0577 - mse: 97.0577\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 69.4299 - mse: 69.4299\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 80.6937 - mse: 80.6937\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 63.1489 - mse: 63.1489\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 58.3987 - mse: 58.3987\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 61.1668 - mse: 61.1668\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 77.1607 - mse: 77.1607\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 60.8565 - mse: 60.8565\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 75.4168 - mse: 75.4168\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 60.3345 - mse: 60.3345\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 62.4137 - mse: 62.4137\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 67.5089 - mse: 67.5089\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 56.8078 - mse: 56.8078\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 59.1539 - mse: 59.1539\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 56.8000 - mse: 56.8000\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 53.3272 - mse: 53.3272\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 78.1152 - mse: 78.1152\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 54.9049 - mse: 54.9049\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 53.2718 - mse: 53.2718\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 51.8927 - mse: 51.8927\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 54.8647 - mse: 54.8647\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 56.1398 - mse: 56.1398\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 64.1435 - mse: 64.1435\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 61.0760 - mse: 61.0760\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "historydf = pd.concat(dflist,axis=1)\n",
        "metrics_reported = dflist[0].columns\n",
        "idx = pd.MultiIndex.from_product([optimizers,metrics_reported],names=['optimizers','metric'])\n",
        "\n",
        "idx.shape\n",
        "historydf.columns = idx\n",
        "\n",
        "print(historydf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzyuoEaGgUPN",
        "outputId": "16d08970-53a4-418d-d492-758351b9817e"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "optimizers keras.optimizers.Adam()  ... keras.optimizers.RMSprop()\n",
            "metric                        loss  ...                        mse\n",
            "0                       517.110657  ...                 339.639893\n",
            "1                       265.042236  ...                  97.057655\n",
            "2                       161.319305  ...                  69.429932\n",
            "3                       157.156570  ...                  80.693718\n",
            "4                       135.371002  ...                  63.148941\n",
            "5                       101.686119  ...                  58.398689\n",
            "6                        86.614731  ...                  61.166836\n",
            "7                        75.878876  ...                  77.160744\n",
            "8                        66.762848  ...                  60.856522\n",
            "9                        65.216103  ...                  75.416817\n",
            "10                       63.724949  ...                  60.334476\n",
            "11                       61.807602  ...                  62.413723\n",
            "12                       62.074242  ...                  67.508896\n",
            "13                       60.925251  ...                  56.807774\n",
            "14                       58.769131  ...                  59.153877\n",
            "15                       59.507652  ...                  56.799992\n",
            "16                       57.291687  ...                  53.327240\n",
            "17                       57.720673  ...                  78.115242\n",
            "18                       56.450661  ...                  54.904877\n",
            "19                       55.363674  ...                  53.271755\n",
            "20                       55.420628  ...                  51.892654\n",
            "21                       54.550575  ...                  54.864716\n",
            "22                       53.838257  ...                  56.139759\n",
            "23                       53.478062  ...                  64.143539\n",
            "24                       53.156418  ...                  61.076004\n",
            "\n",
            "[25 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Initializers"
      ],
      "metadata": {
        "id": "S9vmBMWEg30z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dflist = []\n",
        "\n",
        "initializers = ['zeros','uniform','normal','he_normal','lecun_uniform']\n",
        "\n",
        "for init in initializers:\n",
        "  # Initialising the ANN\n",
        "  Regressor = Sequential()\n",
        "\n",
        "  # Adding the input layer and the first hidden layer\n",
        "  Regressor.add(Dense(units = 100, kernel_initializer = init, activation = 'relu', input_dim = 13))\n",
        "\n",
        "  # Adding the second hidden layer\n",
        "  Regressor.add(Dense(units = 50, kernel_initializer = init, activation = 'relu'))\n",
        "\n",
        "  # Adding the output layer\n",
        "  Regressor.add(Dense(units = 1))\n",
        "\n",
        "  # Compiling the ANN\n",
        "  Regressor.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics=['mse'])\n",
        "\n",
        "  h = Regressor.fit(X_train,y_train,epochs=25,batch_size=bs,verbose=1)\n",
        "    \n",
        "  dflist.append(pd.DataFrame(h.history,index=h.epoch))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hi4ABJrIg4jx",
        "outputId": "ac0cd19c-b038-423b-98ac-19c06802b4c8"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "4/4 [==============================] - 1s 4ms/step - loss: 596.3922 - mse: 596.3922\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 596.2093 - mse: 596.2093\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 596.0302 - mse: 596.0302\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 595.8491 - mse: 595.8491\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 595.6684 - mse: 595.6684\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 595.4888 - mse: 595.4888\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 595.3078 - mse: 595.3078\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 595.1243 - mse: 595.1243\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 594.9438 - mse: 594.9438\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 594.7618 - mse: 594.7618\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 594.5793 - mse: 594.5793\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 594.3990 - mse: 594.3990\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 594.2180 - mse: 594.2180\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 594.0389 - mse: 594.0389\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 593.8610 - mse: 593.8610\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 593.6850 - mse: 593.6850\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 593.5081 - mse: 593.5081\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 593.3297 - mse: 593.3297\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 593.1521 - mse: 593.1521\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 592.9715 - mse: 592.9715\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 592.7917 - mse: 592.7917\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 592.6104 - mse: 592.6104\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 592.4314 - mse: 592.4314\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 592.2528 - mse: 592.2528\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 592.0726 - mse: 592.0726\n",
            "Epoch 1/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 744.5906 - mse: 744.5906\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 284.2816 - mse: 284.2816\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 155.3976 - mse: 155.3976\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 168.0071 - mse: 168.0071\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 143.7321 - mse: 143.7321\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 97.3943 - mse: 97.3943\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 79.1418 - mse: 79.1418\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 70.6245 - mse: 70.6245\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 62.6157 - mse: 62.6157\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 60.7434 - mse: 60.7434\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 59.9592 - mse: 59.9592\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 58.3350 - mse: 58.3350\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 58.7041 - mse: 58.7041\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 58.5250 - mse: 58.5250\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 57.0108 - mse: 57.0108\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 56.0273 - mse: 56.0273\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 55.3374 - mse: 55.3374\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 54.6367 - mse: 54.6367\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 54.0365 - mse: 54.0365\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 53.7345 - mse: 53.7345\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 53.7312 - mse: 53.7312\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 53.5436 - mse: 53.5436\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 52.7622 - mse: 52.7622\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 53.0611 - mse: 53.0611\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 52.7780 - mse: 52.7780\n",
            "Epoch 1/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 575.3521 - mse: 575.3521\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 156.0822 - mse: 156.0822\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 229.9682 - mse: 229.9682\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 104.3442 - mse: 104.3442\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 88.3129 - mse: 88.3129\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 92.6763 - mse: 92.6763\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 64.2491 - mse: 64.2491\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 66.4023 - mse: 66.4023\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 68.7266 - mse: 68.7266\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 58.6792 - mse: 58.6792\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 61.5018 - mse: 61.5018\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 58.2468 - mse: 58.2468\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 56.6768 - mse: 56.6768\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 57.4285 - mse: 57.4285\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 55.1006 - mse: 55.1006\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 54.5396 - mse: 54.5396\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 54.0008 - mse: 54.0008\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 54.2331 - mse: 54.2331\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 53.6151 - mse: 53.6151\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 53.3533 - mse: 53.3533\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 53.0542 - mse: 53.0542\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 52.6285 - mse: 52.6285\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 52.5434 - mse: 52.5434\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 51.7959 - mse: 51.7959\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 51.8191 - mse: 51.8191\n",
            "Epoch 1/25\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 5333.5859 - mse: 5333.5859\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4232.4360 - mse: 4232.4360\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 600.9655 - mse: 600.9655\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1546.4321 - mse: 1546.4321\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 351.3442 - mse: 351.3442\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 696.2465 - mse: 696.2465\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 242.0237 - mse: 242.0237\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 317.9155 - mse: 317.9155\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 171.1085 - mse: 171.1085\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 196.8724 - mse: 196.8724\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 123.1556 - mse: 123.1556\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 126.6091 - mse: 126.6091\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 96.4617 - mse: 96.4617\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 101.0222 - mse: 101.0222\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 92.8172 - mse: 92.8172\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 89.5999 - mse: 89.5999\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 88.3317 - mse: 88.3317\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 84.4836 - mse: 84.4836\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 82.8839 - mse: 82.8839\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 77.9486 - mse: 77.9486\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 75.0115 - mse: 75.0115\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 73.8016 - mse: 73.8016\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 73.0406 - mse: 73.0406\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 71.6180 - mse: 71.6180\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 70.2881 - mse: 70.2881\n",
            "Epoch 1/25\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 22883.1367 - mse: 22883.1367\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1907.7336 - mse: 1907.7336\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6357.2007 - mse: 6357.2007\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 2119.7375 - mse: 2119.7375\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 397.0139 - mse: 397.0139\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1418.8162 - mse: 1418.8162\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 772.2955 - mse: 772.2955\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 171.3361 - mse: 171.3361\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 478.3005 - mse: 478.3005\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 352.1896 - mse: 352.1896\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 118.4634 - mse: 118.4634\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 188.3296 - mse: 188.3296\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 149.0177 - mse: 149.0177\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 90.0937 - mse: 90.0937\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 120.4385 - mse: 120.4385\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 97.6040 - mse: 97.6040\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 87.2350 - mse: 87.2350\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 91.7153 - mse: 91.7153\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 78.3804 - mse: 78.3804\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 78.2192 - mse: 78.2192\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 76.3987 - mse: 76.3987\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 74.3487 - mse: 74.3487\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 74.2250 - mse: 74.2250\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 71.2984 - mse: 71.2984\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 69.9690 - mse: 69.9690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "historydf = pd.concat(dflist,axis=1)\n",
        "metrics_reported = dflist[0].columns\n",
        "idx = pd.MultiIndex.from_product([initializers,metrics_reported],names=['initializers','metric'])\n",
        "\n",
        "idx.shape\n",
        "historydf.columns = idx\n",
        "\n",
        "print(historydf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGZK9r-VhVQK",
        "outputId": "8860ac27-6c99-4548-a76f-f278abd7fd15"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initializers       zeros              ... lecun_uniform              \n",
            "metric              loss         mse  ...          loss           mse\n",
            "0             596.392151  596.392151  ...  22883.136719  22883.136719\n",
            "1             596.209290  596.209290  ...   1907.733643   1907.733643\n",
            "2             596.030151  596.030151  ...   6357.200684   6357.200684\n",
            "3             595.849060  595.849060  ...   2119.737549   2119.737549\n",
            "4             595.668396  595.668396  ...    397.013885    397.013885\n",
            "5             595.488770  595.488770  ...   1418.816162   1418.816162\n",
            "6             595.307800  595.307800  ...    772.295532    772.295532\n",
            "7             595.124329  595.124329  ...    171.336075    171.336075\n",
            "8             594.943848  594.943848  ...    478.300476    478.300476\n",
            "9             594.761780  594.761780  ...    352.189575    352.189575\n",
            "10            594.579285  594.579285  ...    118.463432    118.463432\n",
            "11            594.399048  594.399048  ...    188.329575    188.329575\n",
            "12            594.217957  594.217957  ...    149.017746    149.017746\n",
            "13            594.038879  594.038879  ...     90.093704     90.093704\n",
            "14            593.860962  593.860962  ...    120.438454    120.438454\n",
            "15            593.684998  593.684998  ...     97.603981     97.603981\n",
            "16            593.508057  593.508057  ...     87.234955     87.234955\n",
            "17            593.329651  593.329651  ...     91.715279     91.715279\n",
            "18            593.152100  593.152100  ...     78.380402     78.380402\n",
            "19            592.971497  592.971497  ...     78.219193     78.219193\n",
            "20            592.791748  592.791748  ...     76.398720     76.398720\n",
            "21            592.610352  592.610352  ...     74.348701     74.348701\n",
            "22            592.431396  592.431396  ...     74.224960     74.224960\n",
            "23            592.252808  592.252808  ...     71.298386     71.298386\n",
            "24            592.072632  592.072632  ...     69.968979     69.968979\n",
            "\n",
            "[25 rows x 10 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#With L1 Regularization"
      ],
      "metadata": {
        "id": "GgbOH6ZYrgNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the Keras libraries and packages\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras import regularizers\n",
        "\n",
        "# Initialising the ANN\n",
        "Regressor = Sequential()\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "Regressor.add(Dense(units = 100, kernel_initializer = 'uniform',kernel_regularizer=regularizers.l1(1e-5), activation = 'relu', input_dim = 13))\n",
        "\n",
        "# Adding the second hidden layer\n",
        "Regressor.add(Dense(units = 50, kernel_initializer = 'uniform',kernel_regularizer=regularizers.l1(1e-5), activation = 'relu'))\n",
        "\n",
        "# Adding the output layer\n",
        "Regressor.add(Dense(units = 1))\n",
        "\n",
        "# Compiling the ANN\n",
        "Regressor.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics=[\"mean_squared_error\"])\n",
        "\n",
        "# Fitting the ANN to the Training set\n",
        "Regressor.fit(X_train, y_train, batch_size = 10, epochs = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAzN_SGPrhEm",
        "outputId": "ccd9f076-7312-4240-ef86-395728a977d9"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "41/41 [==============================] - 1s 2ms/step - loss: 124.2260 - mean_squared_error: 124.2248\n",
            "Epoch 2/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 63.5796 - mean_squared_error: 63.5786\n",
            "Epoch 3/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 54.1871 - mean_squared_error: 54.1861\n",
            "Epoch 4/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 60.4476 - mean_squared_error: 60.4466\n",
            "Epoch 5/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 52.9617 - mean_squared_error: 52.9606\n",
            "Epoch 6/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 45.9720 - mean_squared_error: 45.9709\n",
            "Epoch 7/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 43.4763 - mean_squared_error: 43.4752\n",
            "Epoch 8/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 43.3617 - mean_squared_error: 43.3606\n",
            "Epoch 9/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 42.6258 - mean_squared_error: 42.6246\n",
            "Epoch 10/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 35.0803 - mean_squared_error: 35.0791\n",
            "Epoch 11/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 32.4139 - mean_squared_error: 32.4127\n",
            "Epoch 12/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 34.1798 - mean_squared_error: 34.1785\n",
            "Epoch 13/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 32.1664 - mean_squared_error: 32.1651\n",
            "Epoch 14/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 30.1104 - mean_squared_error: 30.1091\n",
            "Epoch 15/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 26.7396 - mean_squared_error: 26.7383\n",
            "Epoch 16/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 30.4189 - mean_squared_error: 30.4175\n",
            "Epoch 17/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 30.1264 - mean_squared_error: 30.1250\n",
            "Epoch 18/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 25.4891 - mean_squared_error: 25.4877\n",
            "Epoch 19/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 25.1757 - mean_squared_error: 25.1742\n",
            "Epoch 20/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 22.9796 - mean_squared_error: 22.9782\n",
            "Epoch 21/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 22.2642 - mean_squared_error: 22.2627\n",
            "Epoch 22/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 25.1753 - mean_squared_error: 25.1738\n",
            "Epoch 23/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 23.1961 - mean_squared_error: 23.1946\n",
            "Epoch 24/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 21.1444 - mean_squared_error: 21.1429\n",
            "Epoch 25/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 22.2330 - mean_squared_error: 22.2314\n",
            "Epoch 26/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 21.7590 - mean_squared_error: 21.7574\n",
            "Epoch 27/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 19.8671 - mean_squared_error: 19.8656\n",
            "Epoch 28/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 20.5032 - mean_squared_error: 20.5016\n",
            "Epoch 29/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 19.4300 - mean_squared_error: 19.4284\n",
            "Epoch 30/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 21.2143 - mean_squared_error: 21.2127\n",
            "Epoch 31/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 20.9329 - mean_squared_error: 20.9313\n",
            "Epoch 32/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 18.0382 - mean_squared_error: 18.0366\n",
            "Epoch 33/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 20.4304 - mean_squared_error: 20.4288\n",
            "Epoch 34/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 21.8508 - mean_squared_error: 21.8491\n",
            "Epoch 35/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 18.8424 - mean_squared_error: 18.8408\n",
            "Epoch 36/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 21.1157 - mean_squared_error: 21.1141\n",
            "Epoch 37/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 19.2710 - mean_squared_error: 19.2693\n",
            "Epoch 38/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 18.0854 - mean_squared_error: 18.0837\n",
            "Epoch 39/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 20.9930 - mean_squared_error: 20.9913\n",
            "Epoch 40/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 17.1810 - mean_squared_error: 17.1793\n",
            "Epoch 41/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 21.7868 - mean_squared_error: 21.7851\n",
            "Epoch 42/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 18.8440 - mean_squared_error: 18.8423\n",
            "Epoch 43/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.9299 - mean_squared_error: 15.9282\n",
            "Epoch 44/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 22.0637 - mean_squared_error: 22.0619\n",
            "Epoch 45/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 17.5246 - mean_squared_error: 17.5229\n",
            "Epoch 46/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.9973 - mean_squared_error: 15.9956\n",
            "Epoch 47/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 19.0218 - mean_squared_error: 19.0201\n",
            "Epoch 48/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 17.3233 - mean_squared_error: 17.3215\n",
            "Epoch 49/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 16.1797 - mean_squared_error: 16.1779\n",
            "Epoch 50/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 17.2991 - mean_squared_error: 17.2973\n",
            "Epoch 51/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 20.9258 - mean_squared_error: 20.9240\n",
            "Epoch 52/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.7620 - mean_squared_error: 15.7603\n",
            "Epoch 53/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 17.1246 - mean_squared_error: 17.1229\n",
            "Epoch 54/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 20.7786 - mean_squared_error: 20.7768\n",
            "Epoch 55/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 21.0856 - mean_squared_error: 21.0838\n",
            "Epoch 56/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 19.5204 - mean_squared_error: 19.5186\n",
            "Epoch 57/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 17.3822 - mean_squared_error: 17.3804\n",
            "Epoch 58/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 19.2030 - mean_squared_error: 19.2012\n",
            "Epoch 59/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 13.9638 - mean_squared_error: 13.9620\n",
            "Epoch 60/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.4313 - mean_squared_error: 14.4295\n",
            "Epoch 61/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.5109 - mean_squared_error: 14.5091\n",
            "Epoch 62/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 21.0053 - mean_squared_error: 21.0035\n",
            "Epoch 63/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.7713 - mean_squared_error: 14.7695\n",
            "Epoch 64/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.6169 - mean_squared_error: 14.6151\n",
            "Epoch 65/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.3817 - mean_squared_error: 14.3799\n",
            "Epoch 66/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 16.3528 - mean_squared_error: 16.3509\n",
            "Epoch 67/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.3112 - mean_squared_error: 15.3093\n",
            "Epoch 68/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.6972 - mean_squared_error: 14.6953\n",
            "Epoch 69/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.5072 - mean_squared_error: 14.5053\n",
            "Epoch 70/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 13.6351 - mean_squared_error: 13.6332\n",
            "Epoch 71/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.2899 - mean_squared_error: 15.2881\n",
            "Epoch 72/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 16.8424 - mean_squared_error: 16.8406\n",
            "Epoch 73/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.8840 - mean_squared_error: 14.8821\n",
            "Epoch 74/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.0817 - mean_squared_error: 14.0798\n",
            "Epoch 75/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 12.7176 - mean_squared_error: 12.7157\n",
            "Epoch 76/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.7561 - mean_squared_error: 14.7542\n",
            "Epoch 77/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.3920 - mean_squared_error: 15.3901\n",
            "Epoch 78/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 16.5984 - mean_squared_error: 16.5965\n",
            "Epoch 79/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.6496 - mean_squared_error: 15.6477\n",
            "Epoch 80/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.1938 - mean_squared_error: 14.1919\n",
            "Epoch 81/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.5335 - mean_squared_error: 14.5316\n",
            "Epoch 82/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 13.9768 - mean_squared_error: 13.9749\n",
            "Epoch 83/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.0430 - mean_squared_error: 14.0411\n",
            "Epoch 84/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 17.1139 - mean_squared_error: 17.1120\n",
            "Epoch 85/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 16.1392 - mean_squared_error: 16.1373\n",
            "Epoch 86/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.7325 - mean_squared_error: 15.7306\n",
            "Epoch 87/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 13.2215 - mean_squared_error: 13.2196\n",
            "Epoch 88/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.8953 - mean_squared_error: 14.8934\n",
            "Epoch 89/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.0201 - mean_squared_error: 15.0182\n",
            "Epoch 90/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.5271 - mean_squared_error: 15.5252\n",
            "Epoch 91/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 18.5701 - mean_squared_error: 18.5682\n",
            "Epoch 92/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 12.9750 - mean_squared_error: 12.9731\n",
            "Epoch 93/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.8332 - mean_squared_error: 14.8313\n",
            "Epoch 94/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.6659 - mean_squared_error: 14.6640\n",
            "Epoch 95/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.9122 - mean_squared_error: 15.9103\n",
            "Epoch 96/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 12.9801 - mean_squared_error: 12.9781\n",
            "Epoch 97/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.8791 - mean_squared_error: 14.8771\n",
            "Epoch 98/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 13.5789 - mean_squared_error: 13.5770\n",
            "Epoch 99/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.9347 - mean_squared_error: 14.9328\n",
            "Epoch 100/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 13.7926 - mean_squared_error: 13.7907\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6d64b4e2d0>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting the Test set results\n",
        "y_pred = Regressor.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import r2_score,mean_squared_error\n",
        "score = np.sqrt(mean_squared_error(y_test,y_pred))\n",
        "print (\"mean_squared_error: \",score)\n",
        "\n",
        "r2_score = r2_score(y_test,y_pred)\n",
        "print(\"r2_score: \",r2_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0O7CiqvOsGCE",
        "outputId": "7e0ed9ba-2df5-4bd9-f4ee-23f68e0463d2"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_squared_error:  5.409941481789402\n",
            "r2_score:  0.6405743844096344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#With L2 Regularization"
      ],
      "metadata": {
        "id": "q3jgravzsfWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the Keras libraries and packages\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras import regularizers\n",
        "\n",
        "# Initialising the ANN\n",
        "Regressor = Sequential()\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "Regressor.add(Dense(units = 100, kernel_initializer = 'uniform',kernel_regularizer=regularizers.l2(1e-4), activation = 'relu', input_dim = 13))\n",
        "\n",
        "# Adding the second hidden layer\n",
        "Regressor.add(Dense(units = 50, kernel_initializer = 'uniform',kernel_regularizer=regularizers.l2(1e-4), activation = 'relu'))\n",
        "\n",
        "# Adding the output layer\n",
        "Regressor.add(Dense(units = 1))\n",
        "\n",
        "# Compiling the ANN\n",
        "Regressor.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics=[\"mean_squared_error\"])\n",
        "\n",
        "# Fitting the ANN to the Training set\n",
        "Regressor.fit(X_train, y_train, batch_size = 10, epochs = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLseIK5CshN0",
        "outputId": "ba493ca7-5096-4b96-88bb-4097e4db4d9c"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "41/41 [==============================] - 1s 2ms/step - loss: 109.8979 - mean_squared_error: 109.8975\n",
            "Epoch 2/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 60.9430 - mean_squared_error: 60.9427\n",
            "Epoch 3/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 58.0061 - mean_squared_error: 58.0058\n",
            "Epoch 4/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 53.4379 - mean_squared_error: 53.4375\n",
            "Epoch 5/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 48.5561 - mean_squared_error: 48.5558\n",
            "Epoch 6/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 47.7090 - mean_squared_error: 47.7085\n",
            "Epoch 7/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 42.0570 - mean_squared_error: 42.0566\n",
            "Epoch 8/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 42.3214 - mean_squared_error: 42.3208\n",
            "Epoch 9/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 41.9358 - mean_squared_error: 41.9353\n",
            "Epoch 10/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 40.2796 - mean_squared_error: 40.2789\n",
            "Epoch 11/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 40.3960 - mean_squared_error: 40.3953\n",
            "Epoch 12/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 32.2878 - mean_squared_error: 32.2870\n",
            "Epoch 13/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 31.4764 - mean_squared_error: 31.4756\n",
            "Epoch 14/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 29.1085 - mean_squared_error: 29.1076\n",
            "Epoch 15/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 26.6262 - mean_squared_error: 26.6253\n",
            "Epoch 16/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 29.2797 - mean_squared_error: 29.2788\n",
            "Epoch 17/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 30.4867 - mean_squared_error: 30.4857\n",
            "Epoch 18/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 27.9291 - mean_squared_error: 27.9280\n",
            "Epoch 19/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 25.0170 - mean_squared_error: 25.0159\n",
            "Epoch 20/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 24.1703 - mean_squared_error: 24.1691\n",
            "Epoch 21/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 24.5884 - mean_squared_error: 24.5872\n",
            "Epoch 22/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 25.5567 - mean_squared_error: 25.5555\n",
            "Epoch 23/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 21.8021 - mean_squared_error: 21.8008\n",
            "Epoch 24/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 29.2455 - mean_squared_error: 29.2441\n",
            "Epoch 25/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 24.0814 - mean_squared_error: 24.0800\n",
            "Epoch 26/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 20.7436 - mean_squared_error: 20.7422\n",
            "Epoch 27/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 22.6223 - mean_squared_error: 22.6208\n",
            "Epoch 28/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 26.8910 - mean_squared_error: 26.8895\n",
            "Epoch 29/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 21.6313 - mean_squared_error: 21.6297\n",
            "Epoch 30/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 21.0417 - mean_squared_error: 21.0401\n",
            "Epoch 31/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 21.8893 - mean_squared_error: 21.8877\n",
            "Epoch 32/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 19.3542 - mean_squared_error: 19.3525\n",
            "Epoch 33/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 18.0465 - mean_squared_error: 18.0448\n",
            "Epoch 34/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 19.9574 - mean_squared_error: 19.9556\n",
            "Epoch 35/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 20.1067 - mean_squared_error: 20.1049\n",
            "Epoch 36/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 17.4951 - mean_squared_error: 17.4933\n",
            "Epoch 37/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 17.2482 - mean_squared_error: 17.2464\n",
            "Epoch 38/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 18.6968 - mean_squared_error: 18.6949\n",
            "Epoch 39/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 16.9929 - mean_squared_error: 16.9910\n",
            "Epoch 40/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 18.2083 - mean_squared_error: 18.2064\n",
            "Epoch 41/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 16.6668 - mean_squared_error: 16.6649\n",
            "Epoch 42/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.6434 - mean_squared_error: 15.6415\n",
            "Epoch 43/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 17.5528 - mean_squared_error: 17.5509\n",
            "Epoch 44/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 16.2114 - mean_squared_error: 16.2095\n",
            "Epoch 45/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 18.6050 - mean_squared_error: 18.6030\n",
            "Epoch 46/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.8602 - mean_squared_error: 15.8582\n",
            "Epoch 47/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.4272 - mean_squared_error: 15.4252\n",
            "Epoch 48/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 19.4543 - mean_squared_error: 19.4523\n",
            "Epoch 49/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 16.8855 - mean_squared_error: 16.8835\n",
            "Epoch 50/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 17.8880 - mean_squared_error: 17.8860\n",
            "Epoch 51/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.3026 - mean_squared_error: 14.3005\n",
            "Epoch 52/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 17.6509 - mean_squared_error: 17.6488\n",
            "Epoch 53/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 16.9596 - mean_squared_error: 16.9575\n",
            "Epoch 54/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 16.6331 - mean_squared_error: 16.6310\n",
            "Epoch 55/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 18.2989 - mean_squared_error: 18.2968\n",
            "Epoch 56/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 17.0977 - mean_squared_error: 17.0956\n",
            "Epoch 57/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 17.5939 - mean_squared_error: 17.5918\n",
            "Epoch 58/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 20.1313 - mean_squared_error: 20.1291\n",
            "Epoch 59/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 17.6955 - mean_squared_error: 17.6933\n",
            "Epoch 60/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 16.8758 - mean_squared_error: 16.8736\n",
            "Epoch 61/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 18.0917 - mean_squared_error: 18.0895\n",
            "Epoch 62/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 20.6856 - mean_squared_error: 20.6834\n",
            "Epoch 63/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.6213 - mean_squared_error: 15.6190\n",
            "Epoch 64/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 16.6885 - mean_squared_error: 16.6862\n",
            "Epoch 65/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.6040 - mean_squared_error: 14.6017\n",
            "Epoch 66/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.5131 - mean_squared_error: 15.5108\n",
            "Epoch 67/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.8180 - mean_squared_error: 15.8156\n",
            "Epoch 68/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 16.1197 - mean_squared_error: 16.1174\n",
            "Epoch 69/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.9501 - mean_squared_error: 15.9478\n",
            "Epoch 70/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.8022 - mean_squared_error: 14.7999\n",
            "Epoch 71/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.1689 - mean_squared_error: 15.1666\n",
            "Epoch 72/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 13.4121 - mean_squared_error: 13.4098\n",
            "Epoch 73/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.8418 - mean_squared_error: 14.8394\n",
            "Epoch 74/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.6924 - mean_squared_error: 14.6900\n",
            "Epoch 75/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 16.1388 - mean_squared_error: 16.1364\n",
            "Epoch 76/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.1957 - mean_squared_error: 14.1932\n",
            "Epoch 77/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.5879 - mean_squared_error: 14.5855\n",
            "Epoch 78/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.9804 - mean_squared_error: 15.9780\n",
            "Epoch 79/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 13.1654 - mean_squared_error: 13.1629\n",
            "Epoch 80/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 13.6850 - mean_squared_error: 13.6825\n",
            "Epoch 81/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.6322 - mean_squared_error: 15.6297\n",
            "Epoch 82/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.2650 - mean_squared_error: 15.2625\n",
            "Epoch 83/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 17.5309 - mean_squared_error: 17.5284\n",
            "Epoch 84/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 16.2200 - mean_squared_error: 16.2174\n",
            "Epoch 85/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.6381 - mean_squared_error: 14.6356\n",
            "Epoch 86/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 13.6167 - mean_squared_error: 13.6141\n",
            "Epoch 87/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 17.3666 - mean_squared_error: 17.3640\n",
            "Epoch 88/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.8173 - mean_squared_error: 15.8147\n",
            "Epoch 89/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.4996 - mean_squared_error: 15.4970\n",
            "Epoch 90/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 13.5479 - mean_squared_error: 13.5452\n",
            "Epoch 91/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 13.8082 - mean_squared_error: 13.8055\n",
            "Epoch 92/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.6744 - mean_squared_error: 14.6717\n",
            "Epoch 93/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.1675 - mean_squared_error: 14.1648\n",
            "Epoch 94/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.6850 - mean_squared_error: 14.6823\n",
            "Epoch 95/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 13.7370 - mean_squared_error: 13.7343\n",
            "Epoch 96/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 12.6675 - mean_squared_error: 12.6648\n",
            "Epoch 97/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 13.6789 - mean_squared_error: 13.6762\n",
            "Epoch 98/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.1911 - mean_squared_error: 14.1883\n",
            "Epoch 99/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 13.8461 - mean_squared_error: 13.8434\n",
            "Epoch 100/100\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 16.5336 - mean_squared_error: 16.5308\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6d65222850>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting the Test set results\n",
        "y_pred = Regressor.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import r2_score,mean_squared_error\n",
        "score = np.sqrt(mean_squared_error(y_test,y_pred))\n",
        "print (\"mean_squared_error: \",score)\n",
        "\n",
        "r2_score = r2_score(y_test,y_pred)\n",
        "print(\"r2_score: \",r2_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpNGN57Dsvxr",
        "outputId": "7d3e334e-597a-443f-fb2c-66f383bb2e48"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_squared_error:  6.000600157532399\n",
            "r2_score:  0.557805569339155\n"
          ]
        }
      ]
    }
  ]
}